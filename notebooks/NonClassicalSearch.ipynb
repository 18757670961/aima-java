{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond Classical Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as a supporting material for the chapter **Beyond Classical Search**. The notebooks illustrate the use of the code repository and demonstrate how the code can be extended to solve various search related problems. Classical Search (Chapter 3) addresses a single category of problems: _observable_, _deterministic_, _known environments_ where the solution is a sequence of actions. Here, we look at what happens when these assumptions are relaxed. The discussion begins with the **local search** on state space. Then we examine what happens if we relax the assumptions of determinism and observability. At last, we'll study **online search**, in which the agent is faced with a state space that is initially unknown and must be explored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%classpath add jar ../out/artifacts/aima_core_jar/aima-core.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Search Algorithms and Optimization Problems\n",
    "\n",
    "These algorithms are suitable for problems in which all that matters is the solution state, not the path cost to reach it. For example, in the 8-queens problem, what matters is the final configuration of queens, not the order in which they were added. Therefore, **Local search** algorithms operate using a single **current node** (rather than multiple paths) and generally move only to the neighbours of that node i.e. the paths followed by the search are not retained. In addition to finding goals,local search algorithms are useful for solving pure **optimization problems**, in which the aim is to find the best state according to an **objective function**.\n",
    "\n",
    "To understand local search, we consider the **state-space landscape**. A landscape has both _location_ (defined by the state) and _elevation_ (defined by the value of heuristic cost function or objective function). If elevation corresponds to cost, the aim is to find the **global minimum**; if elevation corresponds to an objctive function, the aim is to find the **global maximum**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hill-climbing Search\n",
    "\n",
    "It is simply a loop that continually moves in the direction of increasing value. It terminates when it reaches a \"peak\" where no neighbour has the higher value. It does not maintain a search tree, so the data structure for the current node need only record the state and value of objective function. Therefore, this algorithm does not look ahead beyond the immediate neighbours of the current state.\n",
    "\n",
    "Hill climbing is sometimes called **greedy local search** because it grabs a good neighbour state without thinking ahead where to go next. It chooses randomly among the set of best successors if there are more than one. Unfortunately, hill climbing often gets stuck for the following reasons:-\n",
    "* **Local maxima**: A local maxima is a peak that is higher than each of its neighbouring states but lower than the global maximum. Hill-climbing algorithms that reach the vicinity of a local maximum will be drawn upwards towards the peak but will then be stuck with nowhere else to go.\n",
    "* **Ridges**: Ridges result in a sequence of local maxima that is very difficult for greedy algorithms to navigate.\n",
    "* **Plateaux**: A plateau is a flat area of the state space landscape. \n",
    "\n",
    "Let's have a look at the pseudo code of hill-climbing search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### AIMA4e\n",
       "\n",
       "__function__ HILL-CLIMBING(_problem_) __returns__ a state that is a local maximum  \n",
       "&emsp;_current_ &larr; _problem_.INITIAL\\-STATE  \n",
       "&emsp;__loop do__  \n",
       "&emsp;&emsp;&emsp;_neighbor_ &larr; a highest\\-valued successor of _current_  \n",
       "&emsp;&emsp;&emsp;_if_ VALUE(_neighbour_) &le; VALUE(_current_) __then return__ _current_  \n",
       "&emsp;&emsp;&emsp;_current_ &larr; _neighbor_  \n",
       "\n",
       "---\n",
       "__Figure 4.2__ The hill-climbing search algorithm, which is the most basic local search technique. At each step the current node is replaced by the best neighbor.\n",
       "\n",
       "## AIMA3e\n",
       "__function__ HILL-CLIMBING(_problem_) __returns__ a state that is a local maximum  \n",
       "&emsp;_current_ &larr; MAKE\\-NODE(_problem_.INITIAL\\-STATE)  \n",
       "&emsp;__loop do__  \n",
       "&emsp;&emsp;&emsp;_neighbor_ &larr; a highest\\-valued successor of _current_  \n",
       "&emsp;&emsp;&emsp;__if__ _neighbor_.VALUE &le; _current_.VALUE __then return__ _current_.STATE  \n",
       "&emsp;&emsp;&emsp;_current_ &larr; _neighbor_\n",
       "\n",
       "---\n",
       "__Figure ??__ The hill\\-climbing search algorithm, which is the most basic local search technique. At each step the current node is replaced by the best neighbor; in this version, that means the neighbor with the highest VALUE, but if a heuristic cost estimate _h_ is used, we would find the neighbor with the lowest _h_."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%python\n",
    "from notebookUtils import *\n",
    "pseudocode('Hill Climbing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the above pseudo code can be viewed [here](https://github.com/aimacode/aima-java/blob/AIMA3e/aima-core/src/main/java/aima/core/search/local/HillClimbingSearch.java). \n",
    "\n",
    "This algorithm halts if it reaches a plateau where the best successor has the same value as the current state. It might be a good idea to allow sideways move in the hope that plateau is really a shoulder, but we must take care. An infinite loop can occur whenever the algorithm reaches a flat local maximum that is not a shoulder. One common solution is to put a limit on the number of consecutive sideways moves allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random-Restart Hill Climbing\n",
    "\n",
    "The hill climbing algorithms described so far are incomplete as they often get stuck on local maxima. Therefore, **Random-restart hill climbing** conducts a series of hill climbing searches from randomly generated initial states, until a goal is found. If each hill climbing has a probability $p$ of success, then the expected number of restarts required is $1/p$. The success of hill climbing dependes very much on the shape of the state space landscape: if there are few local maxima and plateaux, random restart hill climbing will find a good solution very quickly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "text/x-java",
   "file_extension": ".java",
   "mimetype": "",
   "name": "Java",
   "nbconverter_exporter": "",
   "version": "1.8.0_144"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
