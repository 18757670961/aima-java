{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as the supporting material for the chapter **Deep Learning**. In this notebook, we'll learn different activation funtions. Then we'll create a deep neural network using Deeplearning4j and train a model capable of classifying random handwriting digits. \n",
    "\n",
    ">_\"While handwriting recognition has been attempted by different machine learning algorithms over the years, deep learning performs remarkably well and achieves an accuracy of over 99.7% on the MNIST dataset.\"_ \n",
    "\n",
    "So, let's begin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fe019e-ca55-41a7-954f-9017db275a55",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.nd4j nd4j-native-platform 0.9.1\n",
    "org.deeplearning4j deeplearning4j-core 0.9.1\n",
    "org.datavec datavec-api 0.9.1\n",
    "org.datavec datavec-local 0.9.1\n",
    "org.datavec datavec-dataframe 0.9.1\n",
    "org.bytedeco javacpp 1.5\n",
    "org.apache.httpcomponents httpclient 4.3.5\n",
    "org.deeplearning4j deeplearning4j-ui_2.11 0.9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "### 1.) Saturating activation funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783dbb19-778c-4957-ab41-8cd90f1bcb18",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.nd4j.linalg.api.ndarray.INDArray;\n",
    "import org.nd4j.linalg.factory.Nd4j;\n",
    "import org.nd4j.linalg.ops.transforms.Transforms;\n",
    "import org.nd4j.linalg.api.iter.NdIndexIterator;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "INDArray array = Nd4j.linspace(-5,5,200);\n",
    "INDArray sigmoid = Transforms.sigmoid(array);\n",
    "\n",
    "def ch = new Crosshair(color: Color.gray, width: 2, style: StrokeType.DOT);\n",
    "p1 = new Plot(title: \"Sigmoid activation function\", crosshair: ch);\n",
    "p1 << new ConstantLine(x: 0, y: 0, color: Color.black);\n",
    "p1 << new ConstantLine(y: 1, color: Color.black, style: StrokeType.DOT);\n",
    "p1 << new Line(x: [-5, 5], y: [-3/4, 7/4], style: StrokeType.DASH, color: Color.green);\n",
    "p1 << new Line(x: toDoubleArrayList(array), y: toDoubleArrayList(sigmoid), displayName: \"Sigmoid\", color: Color.blue, width: 3);\n",
    "p1 << new Text(x: 0, y: 0.5, text: \"Linear\", pointerAngle: 3.505);\n",
    "p1 << new Text(x: -5, y: 0, text: \"Saturating\", pointerAngle: 1.57);\n",
    "p1 << new Text(x: 5, y: 1, text: \"Saturating\", pointerAngle: 4.71);\n",
    "\n",
    "public List<Double> toDoubleArrayList(INDArray array){\n",
    "    NdIndexIterator iter = new NdIndexIterator(200);\n",
    "    List<Double> list = new ArrayList<Double>();\n",
    "    while (iter.hasNext()) {\n",
    "        int[] nextIndex = iter.next();\n",
    "        double nextVal = array.getDouble(nextIndex);\n",
    "        list.add(nextVal);\n",
    "    }\n",
    "    return list;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236e0403-4982-42e3-8d3f-ef056b927484",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.nd4j.linalg.api.ndarray.INDArray;\n",
    "import org.nd4j.linalg.factory.Nd4j;\n",
    "import org.nd4j.linalg.ops.transforms.Transforms;\n",
    "import org.nd4j.linalg.api.iter.NdIndexIterator;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "INDArray array = Nd4j.linspace(-5,5,200);\n",
    "INDArray relu = Transforms.relu(array);\n",
    "INDArray leakyRelu = Transforms.leakyRelu(array);\n",
    "INDArray elu = Transforms.elu(array);\n",
    "\n",
    "def ch = new Crosshair(color: Color.gray, width: 2, style: StrokeType.DOT);\n",
    "p1 = new Plot(title: \"Non saturating activation function\", crosshair: ch);\n",
    "p1 << new ConstantLine(x: 0, y: 0, color: Color.black);\n",
    "p1 << new ConstantLine(y: -1, color: Color.black, style: StrokeType.DOT);\n",
    "p1.getYAxes()[0].setBound(-1.5,5);\n",
    "p1 << new Line(x: toDoubleArrayList(array), y: toDoubleArrayList(elu), displayName: \"ELU (Î±=1)\", color: Color.red)\n",
    "p1 << new Line(x: toDoubleArrayList(array), y: toDoubleArrayList(relu), displayName: \"ReLU\", color: Color.orange)\n",
    "p1 << new Line(x: toDoubleArrayList(array), y: toDoubleArrayList(leakyRelu), displayName: \"Leaky ReLU\", color: Color.blue);\n",
    "p1 << new Text(x: -5, y: 0, text: \"Leak\", pointerAngle: 1.57);\n",
    "\n",
    "\n",
    "public List<Double> toDoubleArrayList(INDArray array){\n",
    "    NdIndexIterator iter = new NdIndexIterator(200);\n",
    "    List<Double> list = new ArrayList<Double>();\n",
    "    while (iter.hasNext()) {\n",
    "        int[] nextIndex = iter.next();\n",
    "        double nextVal = array.getDouble(nextIndex);\n",
    "        list.add(nextVal);\n",
    "    }\n",
    "    return list;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on MNIST using the Leaky ReLU. \n",
    "\n",
    "We've to create a DataUtils class first, containing methods required for downloading, extracting and deleting the dataset files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package aima.notebooks.deeplearning;\n",
    "\n",
    "import org.apache.commons.compress.archivers.tar.TarArchiveEntry;\n",
    "import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\n",
    "import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\n",
    "import org.apache.http.HttpEntity;\n",
    "import org.apache.http.client.methods.CloseableHttpResponse;\n",
    "import org.apache.http.client.methods.HttpGet;\n",
    "import org.apache.http.impl.client.CloseableHttpClient;\n",
    "import org.apache.http.impl.client.HttpClientBuilder;\n",
    "\n",
    "import java.io.*;\n",
    "import java.nio.file.*;\n",
    "import java.nio.file.attribute.BasicFileAttributes;\n",
    "\n",
    "public class DataUtils{\n",
    "    \n",
    "    public DataUtils(){}\n",
    "    \n",
    "    public boolean downloadFile(String remoteUrl, String localPath) throws IOException {\n",
    "        boolean downloaded = false;\n",
    "        if (remoteUrl == null || localPath == null)\n",
    "            return downloaded;\n",
    "        File file = new File(localPath);\n",
    "        if (!file.exists()) {\n",
    "            file.getParentFile().mkdirs();\n",
    "            HttpClientBuilder builder = HttpClientBuilder.create();\n",
    "            CloseableHttpClient client = builder.build();\n",
    "            try {\n",
    "                CloseableHttpResponse response = client.execute(new HttpGet(remoteUrl))\n",
    "                HttpEntity entity = response.getEntity();\n",
    "                if (entity != null) {\n",
    "                    try {\n",
    "                        FileOutputStream outstream = new FileOutputStream(file)\n",
    "                        entity.writeTo(outstream);\n",
    "                        outstream.flush();\n",
    "                        outstream.close();\n",
    "                    } catch(IOException e){\n",
    "                        System.out.println(e);\n",
    "                    }\n",
    "                }\n",
    "            } catch(IOException e){\n",
    "                System.out.println(e);\n",
    "            }\n",
    "            downloaded = true;\n",
    "        }\n",
    "        if (!file.exists())\n",
    "            throw new IOException(\"File doesn't exist: \" + localPath);\n",
    "        return downloaded;\n",
    "    }\n",
    "    public void extractTarGz(String inputPath, String outputPath) throws IOException {\n",
    "        if (inputPath == null || outputPath == null)\n",
    "            return;\n",
    "        final int bufferSize = 4096;\n",
    "        if (!outputPath.endsWith(\"\" + File.separatorChar))\n",
    "            outputPath = outputPath + File.separatorChar;\n",
    "        try {\n",
    "            TarArchiveInputStream tais = new TarArchiveInputStream(new GzipCompressorInputStream(new BufferedInputStream(new FileInputStream(inputPath))))\n",
    "            TarArchiveEntry entry;\n",
    "            while ((entry = (TarArchiveEntry) tais.getNextEntry()) != null) {\n",
    "                if (entry.isDirectory()) {\n",
    "                    new File(outputPath + entry.getName()).mkdirs();\n",
    "                } else {\n",
    "                    int count;\n",
    "                    byte[] data = new byte[bufferSize];\n",
    "                    FileOutputStream fos = new FileOutputStream(outputPath + entry.getName());\n",
    "                    BufferedOutputStream dest = new BufferedOutputStream(fos, bufferSize);\n",
    "                    while ((count = tais.read(data, 0, bufferSize)) != -1) {\n",
    "                        dest.write(data, 0, count);\n",
    "                    }\n",
    "                    dest.close();\n",
    "                }\n",
    "            }\n",
    "        } catch(IOException e){\n",
    "            System.out.println(e);\n",
    "        }\n",
    "    }\n",
    "    public void deleteDir(String path) throws IOException{\n",
    "        Path directory = Paths.get(path);\n",
    "        Files.walkFileTree(directory, new SimpleFileVisitor<Path>() {\n",
    "            @Override\n",
    "            public FileVisitResult visitFile(Path file, BasicFileAttributes attributes) throws IOException {\n",
    "                Files.delete(file); // this will work because it's always a File\n",
    "                return FileVisitResult.CONTINUE;\n",
    "            }\n",
    "\n",
    "            @Override\n",
    "            public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {\n",
    "                Files.delete(dir); //this will work because Files in the directory are already deleted\n",
    "                return FileVisitResult.CONTINUE;\n",
    "            }\n",
    "        });\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aima.notebooks.deeplearning.DataUtils;\n",
    "import java.io.File;\n",
    "\n",
    "String DATA_URL = \"http://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz\";\n",
    "String BASE_PATH = \"./assets\";\n",
    "String localFilePath = BASE_PATH + \"/mnist_png.tar.gz\";\n",
    "DataUtils dataUtils = new DataUtils();\n",
    "if (!new File(localFilePath).exists()) {\n",
    "    if (dataUtils.downloadFile(DATA_URL, localFilePath)) {\n",
    "        dataUtils.extractTarGz(localFilePath, BASE_PATH);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Evaluation Stats*********\n",
      "\n",
      "Examples labeled as 0 classified by model as 0: 960 times\n",
      "Examples labeled as 0 classified by model as 2: 3 times\n",
      "Examples labeled as 0 classified by model as 3: 2 times\n",
      "Examples labeled as 0 classified by model as 4: 2 times\n",
      "Examples labeled as 0 classified by model as 5: 1 times\n",
      "Examples labeled as 0 classified by model as 6: 2 times\n",
      "Examples labeled as 0 classified by model as 7: 5 times\n",
      "Examples labeled as 0 classified by model as 8: 2 times\n",
      "Examples labeled as 0 classified by model as 9: 3 times\n",
      "Examples labeled as 1 classified by model as 1: 1124 times\n",
      "Examples labeled as 1 classified by model as 2: 2 times\n",
      "Examples labeled as 1 classified by model as 3: 1 times\n",
      "Examples labeled as 1 classified by model as 4: 1 times\n",
      "Examples labeled as 1 classified by model as 5: 1 times\n",
      "Examples labeled as 1 classified by model as 6: 3 times\n",
      "Examples labeled as 1 classified by model as 8: 3 times\n",
      "Examples labeled as 2 classified by model as 0: 3 times\n",
      "Examples labeled as 2 classified by model as 1: 2 times\n",
      "Examples labeled as 2 classified by model as 2: 1009 times\n",
      "Examples labeled as 2 classified by model as 3: 3 times\n",
      "Examples labeled as 2 classified by model as 4: 2 times\n",
      "Examples labeled as 2 classified by model as 6: 2 times\n",
      "Examples labeled as 2 classified by model as 7: 5 times\n",
      "Examples labeled as 2 classified by model as 8: 5 times\n",
      "Examples labeled as 2 classified by model as 9: 1 times\n",
      "Examples labeled as 3 classified by model as 2: 10 times\n",
      "Examples labeled as 3 classified by model as 3: 978 times\n",
      "Examples labeled as 3 classified by model as 5: 7 times\n",
      "Examples labeled as 3 classified by model as 7: 7 times\n",
      "Examples labeled as 3 classified by model as 8: 4 times\n",
      "Examples labeled as 3 classified by model as 9: 4 times\n",
      "Examples labeled as 4 classified by model as 2: 6 times\n",
      "Examples labeled as 4 classified by model as 4: 971 times\n",
      "Examples labeled as 4 classified by model as 6: 1 times\n",
      "Examples labeled as 4 classified by model as 8: 2 times\n",
      "Examples labeled as 4 classified by model as 9: 2 times\n",
      "Examples labeled as 5 classified by model as 0: 4 times\n",
      "Examples labeled as 5 classified by model as 2: 1 times\n",
      "Examples labeled as 5 classified by model as 3: 14 times\n",
      "Examples labeled as 5 classified by model as 4: 4 times\n",
      "Examples labeled as 5 classified by model as 5: 855 times\n",
      "Examples labeled as 5 classified by model as 6: 6 times\n",
      "Examples labeled as 5 classified by model as 7: 1 times\n",
      "Examples labeled as 5 classified by model as 8: 5 times\n",
      "Examples labeled as 5 classified by model as 9: 2 times\n",
      "Examples labeled as 6 classified by model as 0: 5 times\n",
      "Examples labeled as 6 classified by model as 1: 2 times\n",
      "Examples labeled as 6 classified by model as 2: 4 times\n",
      "Examples labeled as 6 classified by model as 3: 1 times\n",
      "Examples labeled as 6 classified by model as 4: 6 times\n",
      "Examples labeled as 6 classified by model as 5: 5 times\n",
      "Examples labeled as 6 classified by model as 6: 931 times\n",
      "Examples labeled as 6 classified by model as 7: 1 times\n",
      "Examples labeled as 6 classified by model as 8: 3 times\n",
      "Examples labeled as 7 classified by model as 1: 10 times\n",
      "Examples labeled as 7 classified by model as 2: 15 times\n",
      "Examples labeled as 7 classified by model as 3: 4 times\n",
      "Examples labeled as 7 classified by model as 4: 4 times\n",
      "Examples labeled as 7 classified by model as 5: 1 times\n",
      "Examples labeled as 7 classified by model as 7: 972 times\n",
      "Examples labeled as 7 classified by model as 8: 1 times\n",
      "Examples labeled as 7 classified by model as 9: 21 times\n",
      "Examples labeled as 8 classified by model as 0: 3 times\n",
      "Examples labeled as 8 classified by model as 2: 6 times\n",
      "Examples labeled as 8 classified by model as 3: 11 times\n",
      "Examples labeled as 8 classified by model as 4: 8 times\n",
      "Examples labeled as 8 classified by model as 5: 4 times\n",
      "Examples labeled as 8 classified by model as 6: 4 times\n",
      "Examples labeled as 8 classified by model as 7: 7 times\n",
      "Examples labeled as 8 classified by model as 8: 923 times\n",
      "Examples labeled as 8 classified by model as 9: 8 times\n",
      "Examples labeled as 9 classified by model as 0: 3 times\n",
      "Examples labeled as 9 classified by model as 1: 7 times\n",
      "Examples labeled as 9 classified by model as 2: 1 times\n",
      "Examples labeled as 9 classified by model as 3: 9 times\n",
      "Examples labeled as 9 classified by model as 4: 32 times\n",
      "Examples labeled as 9 classified by model as 5: 3 times\n",
      "Examples labeled as 9 classified by model as 7: 4 times\n",
      "Examples labeled as 9 classified by model as 8: 1 times\n",
      "Examples labeled as 9 classified by model as 9: 949 times\n",
      "\n",
      "\n",
      "==========================Scores========================================\n",
      " # of classes:    10\n",
      " Accuracy:        0.9672\n",
      " Precision:       0.9674\n",
      " Recall:          0.9669\n",
      " F1 Score:        0.9670\n",
      "Precision, recall & F1: macro-averaged (equally weighted avg. of 10 classes)\n",
      "========================================================================\n",
      "********Example finished*********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.datavec.api.io.labels.ParentPathLabelGenerator;\n",
    "import org.datavec.api.split.FileSplit;\n",
    "import org.datavec.image.loader.NativeImageLoader;\n",
    "import org.datavec.image.recordreader.ImageRecordReader;\n",
    "import org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator;\n",
    "import org.deeplearning4j.eval.Evaluation;\n",
    "import org.deeplearning4j.optimize.listeners.EvaluativeListener;\n",
    "import org.deeplearning4j.optimize.listeners.ScoreIterationListener;\n",
    "import org.deeplearning4j.optimize.api.InvocationType;\n",
    "import org.deeplearning4j.nn.api.OptimizationAlgorithm;\n",
    "import org.deeplearning4j.nn.conf.MultiLayerConfiguration;\n",
    "import org.deeplearning4j.nn.conf.NeuralNetConfiguration;\n",
    "import org.deeplearning4j.nn.conf.Updater;\n",
    "import org.deeplearning4j.nn.conf.inputs.InputType;\n",
    "import org.deeplearning4j.nn.conf.layers.DenseLayer;\n",
    "import org.deeplearning4j.nn.conf.layers.OutputLayer;\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\n",
    "import org.deeplearning4j.nn.weights.WeightInit;\n",
    "import org.deeplearning4j.api.storage.StatsStorage;\n",
    "import org.deeplearning4j.ui.api.UIServer;\n",
    "import org.deeplearning4j.ui.stats.StatsListener;\n",
    "import org.deeplearning4j.ui.storage.FileStatsStorage;\n",
    "import org.nd4j.linalg.activations.Activation;\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.DataNormalization;\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.ImagePreProcessingScaler;\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions;\n",
    "\n",
    "import java.io.File;\n",
    "import java.util.Random;\n",
    "\n",
    "int seed = 123;\n",
    "double learningRate = 0.01;\n",
    "int batchSize = 100;\n",
    "int numEpochs = 1;\n",
    "\n",
    "int height = 28;\n",
    "int width = 28;\n",
    "int channels = 1;\n",
    "int numInput = height * width;\n",
    "int numHidden = 1000;\n",
    "int numOutput = 10;\n",
    "\n",
    "//Prepare data for loading\n",
    "File trainData = new File(\"./assets/mnist_png/training\");\n",
    "FileSplit trainSplit = new FileSplit(trainData, NativeImageLoader.ALLOWED_FORMATS, new Random(seed));\n",
    "ParentPathLabelGenerator labelMaker = new ParentPathLabelGenerator(); // use parent directory name as the image label\n",
    "ImageRecordReader trainRR = new ImageRecordReader(height, width, 1, labelMaker);\n",
    "trainRR.initialize(trainSplit);\n",
    "DataSetIterator trainIter = new RecordReaderDataSetIterator(trainRR, batchSize, 1, numOutput);\n",
    "DataNormalization imageScaler = new ImagePreProcessingScaler();\n",
    "imageScaler.fit(trainIter);\n",
    "trainIter.setPreProcessor(imageScaler);\n",
    "\n",
    "\n",
    "File testData = new File(\"./assets/mnist_png/testing\");\n",
    "FileSplit testSplit = new FileSplit(testData, NativeImageLoader.ALLOWED_FORMATS, new Random(seed));\n",
    "ImageRecordReader testRR = new ImageRecordReader(height, width, 1, labelMaker);\n",
    "testRR.initialize(testSplit);\n",
    "DataSetIterator testIter = new RecordReaderDataSetIterator(testRR, batchSize, 1, numOutput);\n",
    "testIter.setPreProcessor(imageScaler);\n",
    "\n",
    "//Build the neural network\n",
    "MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()\n",
    "        .seed(seed)\n",
    "        .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n",
    "        .updater(Updater.ADAM)\n",
    "        .list()\n",
    "        .layer(0, new DenseLayer.Builder()\n",
    "                .nIn(numInput)\n",
    "                .nOut(numHidden)\n",
    "                .activation(Activation.RELU)\n",
    "                .weightInit(WeightInit.XAVIER)\n",
    "                .build())\n",
    "        .layer(1, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n",
    "                .nIn(numHidden)\n",
    "                .nOut(numOutput)\n",
    "                .activation(Activation.SOFTMAX)\n",
    "                .weightInit(WeightInit.XAVIER)\n",
    "                .build())\n",
    "        .setInputType(InputType.convolutional(height, width, channels))\n",
    "        .build();\n",
    "\n",
    "UIServer uiServer = UIServer.getInstance();\n",
    "StatsStorage statsStorage = new FileStatsStorage(new File(System.getProperty(\"java.io.tmpdir\"), \"ui-dnn-stats.dl4j\"));\n",
    "uiServer.attach(statsStorage);\n",
    "\n",
    "MultiLayerNetwork model = new MultiLayerNetwork(conf);\n",
    "model.init();\n",
    "model.setListeners(new ScoreIterationListener(10), new StatsListener(statsStorage), new EvaluativeListener(testIter, 1, InvocationType.EPOCH_END));\n",
    "\n",
    "\n",
    "//Train the model and evaluate\n",
    "for (int i = 0; i < numEpochs; i++) {\n",
    "    model.fit(trainIter);\n",
    "    System.out.println(\"********Evaluation Stats*********\");\n",
    "    Evaluation eval = model.evaluate(testIter);\n",
    "    System.out.println(eval.stats());\n",
    "\n",
    "    trainIter.reset();\n",
    "    testIter.reset();\n",
    "}\n",
    "\n",
    "System.out.println(\"********Example finished*********\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional networks\n",
    "\n",
    "Convolutional neural networks are the specialized models that are highly efficient for processing information that can be represented in terms of measurements on a grid. This includes images, which are measurements of brightness on a two-dimensional grid, audio waveforms, which can be regarded as a one-dimensional grid across time, and three-dimensional grid data such as 3-D scans used in medical imaging. For a convolutional network, we use 4-dimensional arrays (known as **feature map**) to keep track of the shape of the image. A feature map is split into several **channels**. Each channel describes how a single type of feature appears across the entire image. The feature map is of shape $m*h*w*c$ where:\n",
    "* $m$ is the number of examples to process together in the same batch,\n",
    "* $h$ is the height of the image,\n",
    "* $w$ is the width of the image, and\n",
    "* $c$ is the number of channels.\n",
    "\n",
    "Now let's create a convolutional neural network and train it on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Evaluation Stats*********\n",
      "\n",
      "Examples labeled as 0 classified by model as 0: 967 times\n",
      "Examples labeled as 0 classified by model as 2: 1 times\n",
      "Examples labeled as 0 classified by model as 5: 2 times\n",
      "Examples labeled as 0 classified by model as 7: 2 times\n",
      "Examples labeled as 0 classified by model as 8: 2 times\n",
      "Examples labeled as 0 classified by model as 9: 6 times\n",
      "Examples labeled as 1 classified by model as 1: 1132 times\n",
      "Examples labeled as 1 classified by model as 3: 1 times\n",
      "Examples labeled as 1 classified by model as 5: 1 times\n",
      "Examples labeled as 1 classified by model as 6: 1 times\n",
      "Examples labeled as 2 classified by model as 0: 1 times\n",
      "Examples labeled as 2 classified by model as 1: 2 times\n",
      "Examples labeled as 2 classified by model as 2: 1015 times\n",
      "Examples labeled as 2 classified by model as 3: 3 times\n",
      "Examples labeled as 2 classified by model as 4: 1 times\n",
      "Examples labeled as 2 classified by model as 5: 1 times\n",
      "Examples labeled as 2 classified by model as 7: 7 times\n",
      "Examples labeled as 2 classified by model as 8: 1 times\n",
      "Examples labeled as 2 classified by model as 9: 1 times\n",
      "Examples labeled as 3 classified by model as 2: 1 times\n",
      "Examples labeled as 3 classified by model as 3: 990 times\n",
      "Examples labeled as 3 classified by model as 5: 8 times\n",
      "Examples labeled as 3 classified by model as 7: 2 times\n",
      "Examples labeled as 3 classified by model as 9: 9 times\n",
      "Examples labeled as 4 classified by model as 4: 975 times\n",
      "Examples labeled as 4 classified by model as 9: 7 times\n",
      "Examples labeled as 5 classified by model as 0: 1 times\n",
      "Examples labeled as 5 classified by model as 2: 1 times\n",
      "Examples labeled as 5 classified by model as 3: 4 times\n",
      "Examples labeled as 5 classified by model as 5: 883 times\n",
      "Examples labeled as 5 classified by model as 7: 1 times\n",
      "Examples labeled as 5 classified by model as 9: 2 times\n",
      "Examples labeled as 6 classified by model as 0: 10 times\n",
      "Examples labeled as 6 classified by model as 1: 3 times\n",
      "Examples labeled as 6 classified by model as 2: 1 times\n",
      "Examples labeled as 6 classified by model as 3: 1 times\n",
      "Examples labeled as 6 classified by model as 4: 16 times\n",
      "Examples labeled as 6 classified by model as 5: 27 times\n",
      "Examples labeled as 6 classified by model as 6: 899 times\n",
      "Examples labeled as 6 classified by model as 8: 1 times\n",
      "Examples labeled as 7 classified by model as 1: 4 times\n",
      "Examples labeled as 7 classified by model as 2: 5 times\n",
      "Examples labeled as 7 classified by model as 3: 4 times\n",
      "Examples labeled as 7 classified by model as 7: 1012 times\n",
      "Examples labeled as 7 classified by model as 9: 3 times\n",
      "Examples labeled as 8 classified by model as 0: 4 times\n",
      "Examples labeled as 8 classified by model as 2: 5 times\n",
      "Examples labeled as 8 classified by model as 3: 2 times\n",
      "Examples labeled as 8 classified by model as 4: 4 times\n",
      "Examples labeled as 8 classified by model as 5: 8 times\n",
      "Examples labeled as 8 classified by model as 6: 1 times\n",
      "Examples labeled as 8 classified by model as 7: 4 times\n",
      "Examples labeled as 8 classified by model as 8: 919 times\n",
      "Examples labeled as 8 classified by model as 9: 27 times\n",
      "Examples labeled as 9 classified by model as 1: 2 times\n",
      "Examples labeled as 9 classified by model as 2: 1 times\n",
      "Examples labeled as 9 classified by model as 3: 1 times\n",
      "Examples labeled as 9 classified by model as 4: 6 times\n",
      "Examples labeled as 9 classified by model as 5: 2 times\n",
      "Examples labeled as 9 classified by model as 7: 4 times\n",
      "Examples labeled as 9 classified by model as 9: 993 times\n",
      "\n",
      "\n",
      "==========================Scores========================================\n",
      " # of classes:    10\n",
      " Accuracy:        0.9785\n",
      " Precision:       0.9786\n",
      " Recall:          0.9781\n",
      " F1 Score:        0.9781\n",
      "Precision, recall & F1: macro-averaged (equally weighted avg. of 10 classes)\n",
      "========================================================================\n",
      "********Example finished*********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.datavec.api.io.labels.ParentPathLabelGenerator;\n",
    "import org.datavec.api.split.FileSplit;\n",
    "import org.datavec.image.loader.NativeImageLoader;\n",
    "import org.datavec.image.recordreader.ImageRecordReader;\n",
    "import org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator;\n",
    "import org.deeplearning4j.eval.Evaluation;\n",
    "import org.deeplearning4j.nn.conf.MultiLayerConfiguration;\n",
    "import org.deeplearning4j.nn.conf.NeuralNetConfiguration;\n",
    "import org.deeplearning4j.nn.conf.Updater;\n",
    "import org.deeplearning4j.nn.conf.inputs.InputType;\n",
    "import org.deeplearning4j.nn.conf.layers.ConvolutionLayer;\n",
    "import org.deeplearning4j.nn.conf.layers.DenseLayer;\n",
    "import org.deeplearning4j.nn.conf.layers.OutputLayer;\n",
    "import org.deeplearning4j.nn.conf.layers.SubsamplingLayer;\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\n",
    "import org.deeplearning4j.nn.weights.WeightInit;\n",
    "import org.deeplearning4j.optimize.api.InvocationType;\n",
    "import org.nd4j.linalg.activations.Activation;\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.DataNormalization;\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.ImagePreProcessingScaler;\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions;\n",
    "\n",
    "import java.io.File;\n",
    "import java.util.Random;\n",
    "\n",
    "int seed = 123;\n",
    "double learningRate = 0.01;\n",
    "int batchSize = 100;\n",
    "int numEpochs = 1;\n",
    "\n",
    "int height = 28;\n",
    "int width = 28;\n",
    "int channels = 1;\n",
    "int numInput = height * width;\n",
    "int numHidden = 1000;\n",
    "int numOutput = 10;\n",
    "\n",
    "//Prepare data for loading\n",
    "File trainData = new File(\"./assets/mnist_png/training\");\n",
    "FileSplit trainSplit = new FileSplit(trainData, NativeImageLoader.ALLOWED_FORMATS, new Random(seed));\n",
    "ParentPathLabelGenerator labelMaker = new ParentPathLabelGenerator(); // use parent directory name as the image label\n",
    "ImageRecordReader trainRR = new ImageRecordReader(height, width, 1, labelMaker);\n",
    "trainRR.initialize(trainSplit);\n",
    "DataSetIterator trainIter = new RecordReaderDataSetIterator(trainRR, batchSize, 1, numOutput);\n",
    "DataNormalization imageScaler = new ImagePreProcessingScaler();\n",
    "imageScaler.fit(trainIter);\n",
    "trainIter.setPreProcessor(imageScaler);\n",
    "\n",
    "\n",
    "File testData = new File(\"./assets/mnist_png/testing\");\n",
    "FileSplit testSplit = new FileSplit(testData, NativeImageLoader.ALLOWED_FORMATS, new Random(seed));\n",
    "ImageRecordReader testRR = new ImageRecordReader(height, width, 1, labelMaker);\n",
    "testRR.initialize(testSplit);\n",
    "DataSetIterator testIter = new RecordReaderDataSetIterator(testRR, batchSize, 1, numOutput);\n",
    "testIter.setPreProcessor(imageScaler);\n",
    "\n",
    "//Build the neural network\n",
    "MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()\n",
    "            .seed(seed)\n",
    "            .updater(Updater.ADAM)\n",
    "            .weightInit(WeightInit.XAVIER)\n",
    "            .list()\n",
    "            .layer(0, new ConvolutionLayer.Builder(5, 5)\n",
    "                .nIn(channels)\n",
    "                .stride(1, 1)\n",
    "                .nOut(20)\n",
    "                .activation(Activation.IDENTITY)\n",
    "                .build())\n",
    "            .layer(1, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n",
    "                .kernelSize(2, 2)\n",
    "                .stride(2, 2)\n",
    "                .build())\n",
    "            .layer(2, new ConvolutionLayer.Builder(5, 5)\n",
    "                .stride(1, 1) // nIn need not specified in later layers\n",
    "                .nOut(50)\n",
    "                .activation(Activation.IDENTITY)\n",
    "                .build())\n",
    "            .layer(3, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)\n",
    "                .kernelSize(2, 2)\n",
    "                .stride(2, 2)\n",
    "                .build())\n",
    "            .layer(4, new DenseLayer.Builder().activation(Activation.RELU)\n",
    "                .nOut(500)\n",
    "                .build())\n",
    "            .layer(5, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n",
    "                .nOut(numOutput)\n",
    "                .activation(Activation.SOFTMAX)\n",
    "                .build())\n",
    "            .setInputType(InputType.convolutionalFlat(height, width, channels)) \n",
    "            .build();\n",
    "\n",
    "\n",
    "MultiLayerNetwork model = new MultiLayerNetwork(conf);\n",
    "model.init();\n",
    "\n",
    "//Train the model and evaluate\n",
    "for (int i = 0; i < numEpochs; i++) {\n",
    "    model.fit(trainIter);\n",
    "    System.out.println(\"********Evaluation Stats*********\");\n",
    "    Evaluation eval = model.evaluate(testIter);\n",
    "    System.out.println(eval.stats());\n",
    "\n",
    "    trainIter.reset();\n",
    "    testIter.reset();\n",
    "}\n",
    "\n",
    "System.out.println(\"********Example finished*********\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now delete the MNIST dataset files as they are no longer required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aima.notebooks.deeplearning.DataUtils;\n",
    "import java.io.File;\n",
    "\n",
    "String DATA_URL = \"http://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz\";\n",
    "String BASE_PATH = \"./assets\";\n",
    "String localFilePath = BASE_PATH + \"/mnist_png.tar.gz\";\n",
    "\n",
    "File file = new File(localFilePath);\n",
    "file.delete();\n",
    "DataUtils dataUtils = new DataUtils();\n",
    "dataUtils.deleteDir(BASE_PATH + \"/mnist_png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks are the networks that introduce the concept of time i.e they allow us to define the value of some variable $v$ at time step $t$ in terms of the values of this variable at previous time steps. For example, we can define an update rule: $v_{(t)} = f(v_{(t-1)})$ using some function $f$ of our choice. These networks are particularly well suited for sequence processing tasks as they allow us to operate over the **sequences of vectors**: sequences in the input, the output, or in the most general case both. In the last few years, there has been incredible success applying RNNs to a variety of problems such as speech recognition, language modeling, translation, image captioning and the list goes on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll apply RNN to a simple problem of generating text character by character. So, let's start..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed. Sample:\t                                          \n",
      "Epoch 1 completed. Sample:\t                                          \n",
      "Epoch 2 completed. Sample:\te   aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "Epoch 3 completed. Sample:\teequuikk uukuukkuukuukuukuukkuukuukuukuukk\n",
      "Epoch 4 completed. Sample:\tThe    orororororororororororororororororo\n",
      "Epoch 5 completed. Sample:\tThe     o oooooooooooooooooooooooooooooooo\n",
      "Epoch 6 completed. Sample:\tThhhq       o ogg.g.*jupssooo ogg.jmpssooo\n",
      "Epoch 7 completed. Sample:\tTheqqucccc    o o o o o o o o o o o o o o \n",
      "Epoch 8 completed. Sample:\tThequiccck  o o o o o o o o o o o o o o o \n",
      "Epoch 9 completed. Sample:\tThe quick brove o ox jumps ove o o ox jump\n",
      "Epoch 10 completed. Sample:\tThe quick br o  ox jumps ove a ove a ove a\n",
      "Epoch 11 completed. Sample:\tThe quick br a lazy dog.***Tee  uuick br a\n",
      "Epoch 12 completed. Sample:\tThe quick brown fox jumps over a lazy dog.\n",
      "Epoch 13 completed. Sample:\tThe quick brown fox jumps over a lazy dog.\n",
      "Epoch 14 completed. Sample:\tThe quick brown fox jumps over a lazy dog.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.deeplearning4j.nn.conf.MultiLayerConfiguration;\n",
    "import org.deeplearning4j.nn.conf.NeuralNetConfiguration;\n",
    "import org.deeplearning4j.nn.conf.Updater;\n",
    "import org.deeplearning4j.nn.conf.layers.LSTM;\n",
    "import org.deeplearning4j.nn.conf.layers.RnnOutputLayer;\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\n",
    "import org.deeplearning4j.nn.weights.WeightInit;\n",
    "import org.nd4j.linalg.activations.Activation;\n",
    "import org.nd4j.linalg.api.ndarray.INDArray;\n",
    "import org.nd4j.linalg.api.ops.impl.indexaccum.IMax;\n",
    "import org.nd4j.linalg.dataset.DataSet;\n",
    "import org.nd4j.linalg.factory.Nd4j;\n",
    "import org.nd4j.linalg.api.ops.Op;\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.LinkedHashSet;\n",
    "import java.util.List;\n",
    "\n",
    "int seed = 123;\n",
    "int nHidden = 50;\n",
    "int epochs = 15;\n",
    "\n",
    "//Define a sentence to learn\n",
    "//Add a dummy character in beginning so that the RNN learns the complete sentence.\n",
    "char[] LEARNSTRING = \"*The quick brown fox jumps over a lazy dog.\".toCharArray();\n",
    "\n",
    "LinkedHashSet<Character> LEARNSTRING_CHARS = new LinkedHashSet<>();\n",
    "for (char c : LEARNSTRING) LEARNSTRING_CHARS.add(c);\n",
    "List<Character> LEARNSTRING_CHARS_LIST = new ArrayList<>();\n",
    "LEARNSTRING_CHARS_LIST.addAll(LEARNSTRING_CHARS);\n",
    "\n",
    "\n",
    "//Build the neural network\n",
    "MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()\n",
    "        .seed(seed)\n",
    "        .updater(Updater.ADAM)\n",
    "        .weightInit(WeightInit.XAVIER)\n",
    "        .list()\n",
    "        .layer(0, new LSTM.Builder()\n",
    "                .nIn(LEARNSTRING_CHARS.size())\n",
    "                .nOut(nHidden)\n",
    "                .activation(Activation.TANH)\n",
    "                .build())\n",
    "        .layer(1, new RnnOutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n",
    "                .activation(Activation.SOFTMAX)\n",
    "                .nIn(nHidden)\n",
    "                .nOut(LEARNSTRING_CHARS.size())\n",
    "                .build())\n",
    "        .build();\n",
    "\n",
    "MultiLayerNetwork model = new MultiLayerNetwork(conf);\n",
    "model.init();\n",
    "\n",
    "//Create our training data\n",
    "int[] shape = [1, LEARNSTRING_CHARS_LIST.size(), LEARNSTRING.length]\n",
    "INDArray input = Nd4j.zeros(shape);\n",
    "INDArray labels = Nd4j.zeros(shape);\n",
    "\n",
    "int pos = 0;\n",
    "for (char currChar : LEARNSTRING) {\n",
    "    char nextChar = LEARNSTRING[(pos + 1) % (LEARNSTRING.length)]; //When currChar is the last, take the first character as nextChar.\n",
    "    // Input neuron for current character is 1 at \"pos\"\n",
    "    int[] inputArr = [0, LEARNSTRING_CHARS_LIST.indexOf(currChar), pos];\n",
    "    input.putScalar(inputArr, 1);\n",
    "\n",
    "    // Output neuron for next character is 1 at \"pos\"\n",
    "    int[] labelArr = [0, LEARNSTRING_CHARS_LIST.indexOf(nextChar), pos];\n",
    "    labels.putScalar(labelArr, 1);\n",
    "    pos++;\n",
    "}\n",
    "\n",
    "DataSet trainingData = new DataSet(input, labels);\n",
    "\n",
    "//Train the model and evaluate\n",
    "for (int i = 0; i < epochs; i++) {\n",
    "    model.fit(trainingData);\n",
    "    model.rnnClearPreviousState();\n",
    "\n",
    "    System.out.print(\"Epoch \" + i + \" completed. Sample:\\t\");\n",
    "    //Evaluate\n",
    "    //Put the first character into RNN as an initialisation\n",
    "    int[] testShape = [1, LEARNSTRING_CHARS_LIST.size(), 1]\n",
    "    INDArray testInit = Nd4j.zeros(testShape);\n",
    "    testInit.putScalar(LEARNSTRING_CHARS_LIST.indexOf(LEARNSTRING[0]), 1);\n",
    "\n",
    "    INDArray output = model.rnnTimeStep(testInit);\n",
    "    //output now contains the highest value neuron at such a position which is the index of a character, which the model thinks should come next\n",
    "    //now the model should guess (LEARNSTRING.length - 1) more characters...\n",
    "\n",
    "    for (int j = 0; j < LEARNSTRING.length - 1; j++) {\n",
    "\n",
    "        //First let's process the last output of the model.\n",
    "        int sampledCharacterIndex = Nd4j.getExecutioner().exec(new IMax(output, null, 1),1).getAt(0);\n",
    "        System.out.print(LEARNSTRING_CHARS_LIST.get(sampledCharacterIndex));\n",
    "\n",
    "        //Use the last output as next input\n",
    "        int[] nextInputShape = [1, LEARNSTRING_CHARS_LIST.size(), 1];\n",
    "        INDArray nextInput = Nd4j.zeros(nextInputShape);\n",
    "        nextInput.putScalar(sampledCharacterIndex, 1);\n",
    "        output = model.rnnTimeStep(nextInput);\n",
    "    }\n",
    "    System.out.println();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Java API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is an **open source library for dataflow programming**. In this notebook, weâll go through the basics of TensorFlow and how to use it in Java. Please note that the TensorFlow Java API does not have feature parity with the Python API. Hence, the Java API is most suitable for inference using pre-trained models and for training pre-defined models from a single Java process. Weâll cover later in the notebook, the possible use cases for using the TensorFlow Java API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Graphs and Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow computation basically revolves around 2 fundamental concepts: **Graph** and **Session**.\n",
    "\n",
    "Computations are represented as Graphs in TensorFlow. A TensorFlow computational graph is typically a directed acyclic graph of operation and data. It consists of two elements:\n",
    "* Tensor: These are the core unit of data in TensorFlow. They are represented as the edges in a computational graph, depicting the flow of data through the graph. A tensor can have a shape with any number of dimensions. The number of dimensions in a tensor is usually referred to as its rank. So a scalar is a rank 0 tensor, a vector is a rank 1 tensor, a matrix is a rank 2 tensor, and so on and so forth.\n",
    "* Operation: These are the nodes in a computational graph. They refer to a wide variety of computation that can happen on the tensors feeding into the operation. They often result in tensors as well which emanate from the operation in a computational graph.  \n",
    "\n",
    "Now, a TensorFlow graph is a mere schematic of the computation. It doesnât compute anything, it doesnât hold any values, it just defines the operations that you specified in your code. Such a graph must be run inside what is called a TensorFlow session for the tensors in the graph to be evaluated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to build a graph and run it in a session using the TensorFlow Java API. More precisely, weâll be using TensorFlow Java API to solve the function represented by the following equation: $y = w*x + b$ where constants $w$ and $b$ have the values 3.0 and 2.0 respectively. We'll begin with adding the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca688802-dac1-4297-be86-0fe45af755e9",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.tensorflow tensorflow 1.12.0\n",
    "org.tensorflow proto 1.12.0\n",
    "com.google.guava guava 23.6-jre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.tensorflow.*;\n",
    "\n",
    "\n",
    "//Creating the graph\n",
    "Graph graph = new Graph();\n",
    "\n",
    "//Defining constants\n",
    "Operation w = graph.opBuilder(\"Const\", \"w\")\n",
    "        .setAttr(\"dtype\", DataType.INT32)\n",
    "        .setAttr(\"value\", Tensor.create(3,Integer.class))\n",
    "        .build();\n",
    "\n",
    "Operation b = graph.opBuilder(\"Const\", \"b\")\n",
    "        .setAttr(\"dtype\", DataType.INT32)\n",
    "        .setAttr(\"value\", Tensor.create(2, Integer.class))\n",
    "        .build();\n",
    "\n",
    "//Defining placeholders\n",
    "Operation x = graph.opBuilder(\"Placeholder\", \"input\")\n",
    "        .setAttr(\"dtype\", DataType.INT32)\n",
    "        .build();\n",
    "\n",
    "//Defining functions\n",
    "Operation wx = graph.opBuilder(\"Mul\", \"wx\")\n",
    "        .addInput(w.output(0))\n",
    "        .addInput(x.output(0))\n",
    "        .build();\n",
    "\n",
    "Operation y = graph.opBuilder(\"Add\", \"y\")\n",
    "        .addInput(wx.output(0))\n",
    "        .addInput(b.output(0))\n",
    "        .build();\n",
    "\n",
    "//Running a session\n",
    "Session session = new Session(graph);\n",
    "Tensor<Integer> tensor = session.runner().fetch(\"y\")\n",
    "        .feed(\"input\", Tensor.create(4, Integer.class))\n",
    "        .run().get(0).expect(Integer.class);\n",
    "\n",
    "//Expected ans: (3*4)+2 = 14\n",
    "System.out.println(tensor.intValue());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a model using TensorFlow Java API. As mentioned earlier, the Java API is suitable for training **pre-defined models**, therefore we'll use the file `graph.pb`, which is generated by executing [create_graph.py](https://github.com/tensorflow/models/blob/master/samples/languages/java/training/model/create_graph.py) in Python. The model in `graph.pb` represents a simple linear model: $y = w*x + b$. The training generates the data of the form $y = 3.0*x + 2.0$, and over time, the model should learn and the value of $w$ should converge to 3.0, and $b$ to 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from       : W = 5.000000\tb = 3.000000\n",
      "After   500 examples: W = 3.582360\tb = 1.685081\n",
      "After  1000 examples: W = 3.300375\tb = 1.842798\n",
      "After  1500 examples: W = 3.162860\tb = 1.923557\n",
      "After  2000 examples: W = 3.082207\tb = 1.956739\n",
      "After  2500 examples: W = 3.043701\tb = 1.975783\n",
      "For input 1.000000, produced 5.019485 (ideally would produce 3*1.000000 + 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "java.io.PrintStream@4ff231c7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.tensorflow.*;\n",
    "\n",
    "import java.nio.file.Files;\n",
    "import java.nio.file.Paths;\n",
    "import java.util.List;\n",
    "import java.util.Random;\n",
    "\n",
    "final byte[] graphDef = Files.readAllBytes(Paths.get(\"./assets/training/graph.pb\"));\n",
    "\n",
    "try {\n",
    "    Graph graph = new Graph();\n",
    "     Session sess = new Session(graph); \n",
    "    graph.importGraphDef(graphDef);\n",
    "\n",
    "    sess.runner().addTarget(\"init\").run();\n",
    "\n",
    "    System.out.print(\"Starting from       : \");\n",
    "    printVariables(sess);\n",
    "\n",
    "    // Train a bunch of times.\n",
    "    final Random r = new Random();\n",
    "    final int NUM_EXAMPLES = 500;\n",
    "    for (int i = 1; i <= 5; i++) {\n",
    "        for (int n = 0; n < NUM_EXAMPLES; n++) {\n",
    "            Float inp = r.nextFloat();\n",
    "            try {\n",
    "                Tensor<Float> input = Tensors.create((float)inp);\n",
    "                 Tensor<Float> target = Tensors.create((float)(3 * inp + 2));\n",
    "                sess.runner().feed(\"input\", input).feed(\"target\", target).addTarget(\"train\").run();\n",
    "            } catch (Exception e){\n",
    "                e.printStackTrace();\n",
    "            }\n",
    "        }\n",
    "        System.out.printf(\"After %5d examples: \", i * NUM_EXAMPLES);\n",
    "        printVariables(sess);\n",
    "    }\n",
    "\n",
    "    // Example of \"inference\" in the same graph:\n",
    "    try {\n",
    "        Tensor<Float> input = Tensors.create(1.0f);\n",
    "         Tensor<Float> output =\n",
    "                 sess.runner().feed(\"input\", input).fetch(\"output\").run().get(0).expect(Float.class);\n",
    "        System.out.printf(\n",
    "                \"For input %f, produced %f (ideally would produce 3*%f + 2)\\n\",\n",
    "                input.floatValue(), output.floatValue(), input.floatValue());\n",
    "    } catch (Exception e){\n",
    "        e.printStackTrace();\n",
    "    }\n",
    "} catch (Exception e){\n",
    "    e.printStackTrace();\n",
    "}\n",
    "\n",
    "private void printVariables(Session sess) {\n",
    "    List<Tensor<?>> values = sess.runner().fetch(\"W/read\").fetch(\"b/read\").run();\n",
    "    System.out.printf(\"W = %f\\tb = %f\\n\", values.get(0).floatValue(), values.get(1).floatValue());\n",
    "    for (Tensor<?> t : values) {\n",
    "        t.close();\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now, we've learned to perform the basic operations using the TensorFlow Java API. But of course, TensorFlow is meant to run graphs much much larger than this. Additionally, the tensors it deals within real-world models are much larger in size and rank. These are the actual machine learning models where TensorFlow finds its real use. \n",
    "\n",
    "Working with the core API in TensorFlow can become really cumbersome as the size of the graph increases. Therefore, TensorFlow provides high-level APIs like Keras to work with complex models. Unfortunately, there is little to no official support for Keras on Java yet. However, we can use Python to define and train complex models either directly in TensorFlow or using high-level APIs like Keras. Subsequently, we can export a trained model and use that in Java using the TensorFlow Java API. This would particularly be useful for situations where we want to use machine learning enabled features in existing clients running on Java. Then there could be several instances where we are interested in the output of a machine learning model but do not necessarily want to create and train that model in Java. This is where TensorFlow Java API finds the bulk of its use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn how this can be achieved, through an example of image classification. We'll be using a pre-trained model [inception5h](https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip) (developed by Google) for classifying the image shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![chair][1]][1]\n",
    "\n",
    "[1]: assets/image_classification/chair.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./assets/image_classification/chair.jpeg --> studio couch    (94.77% likely)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "java.io.PrintStream@4ff231c7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.tensorflow.Graph;\n",
    "import org.tensorflow.Session;\n",
    "import org.tensorflow.Tensor;\n",
    "import org.tensorflow.Tensors;\n",
    "\n",
    "import java.io.BufferedReader;\n",
    "import java.io.FileReader;\n",
    "import java.nio.file.Files;\n",
    "import java.nio.file.Paths;\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "final List<String> labels = new ArrayList<>();\n",
    "String line;\n",
    "BufferedReader reader = new BufferedReader(new FileReader(\"./assets/image_classification/labels.txt\"));\n",
    "while ((line = reader.readLine()) != null) {\n",
    "    labels.add(line);\n",
    "}\n",
    "\n",
    "final byte[] graphDef = Files.readAllBytes(Paths.get(\"./assets/image_classification/graph.pb\"));\n",
    "try{\n",
    "    Graph graph = new Graph();\n",
    "    Session session = new Session(graph);\n",
    "    graph.importGraphDef(graphDef);\n",
    "    \n",
    "    String filename = \"./assets/image_classification/chair.jpeg\";\n",
    "    float[] probabilities = null;\n",
    "    byte[] bytes = Files.readAllBytes(Paths.get(filename));\n",
    "    try {\n",
    "        Tensor<String> input = Tensors.create(bytes);\n",
    "        Tensor<Float> output =\n",
    "                 session\n",
    "                         .runner()\n",
    "                         .feed(\"encoded_image_bytes\", input)\n",
    "                         .fetch(\"probabilities\")\n",
    "                         .run()\n",
    "                         .get(0)\n",
    "                         .expect(Float.class)\n",
    "        if (probabilities == null) {\n",
    "            probabilities = new float[(int) output.shape()[0]];\n",
    "        }\n",
    "        output.copyTo(probabilities);\n",
    "        int label = argmax(probabilities);\n",
    "        System.out.printf(\n",
    "                \"%-30s --> %-15s (%.2f%% likely)\\n\",\n",
    "                filename, labels.get(label), probabilities[label] * 100.0);\n",
    "    } catch(Exception e){\n",
    "        e.printStackTrace();\n",
    "    }\n",
    "} catch(Exception e){\n",
    "    e.printStackTrace();\n",
    "}\n",
    "\n",
    "private int argmax(float[] probabilities) {\n",
    "    int best = 0;\n",
    "    for (int i = 1; i < probabilities.length; ++i) {\n",
    "        if (probabilities[i] > probabilities[best]) {\n",
    "            best = i;\n",
    "        }\n",
    "    }\n",
    "    return best;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this model on other images as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./assets/image_classification/terrier.jpg --> Australian terrier (67.63% likely)\n",
      "./assets/image_classification/terrier2.jpg --> Tibetan terrier (44.09% likely)\n",
      "./assets/image_classification/porcupine.jpg --> porcupine       (85.03% likely)\n",
      "./assets/image_classification/whale.jpg --> killer whale    (41.59% likely)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.tensorflow.Graph;\n",
    "import org.tensorflow.Session;\n",
    "import org.tensorflow.Tensor;\n",
    "import org.tensorflow.Tensors;\n",
    "\n",
    "import java.io.BufferedReader;\n",
    "import java.io.FileReader;\n",
    "import java.nio.file.Files;\n",
    "import java.nio.file.Paths;\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "final List<String> labels = new ArrayList<>();\n",
    "String line;\n",
    "BufferedReader reader = new BufferedReader(new FileReader(\"./assets/image_classification/labels.txt\"));\n",
    "while ((line = reader.readLine()) != null) {\n",
    "    labels.add(line);\n",
    "}\n",
    "\n",
    "final byte[] graphDef = Files.readAllBytes(Paths.get(\"./assets/image_classification/graph.pb\"));\n",
    "try{\n",
    "    Graph graph = new Graph();\n",
    "    Session session = new Session(graph);\n",
    "    graph.importGraphDef(graphDef);\n",
    "    \n",
    "    List<String> filename = new ArrayList<>();\n",
    "    filename.add(\"./assets/image_classification/terrier.jpg\");\n",
    "    filename.add(\"./assets/image_classification/terrier2.jpg\");\n",
    "    filename.add(\"./assets/image_classification/porcupine.jpg\");\n",
    "    filename.add(\"./assets/image_classification/whale.jpg\");\n",
    "    \n",
    "    for(int i = 0; i < filename.size(); ++i){\n",
    "        float[] probabilities = null;\n",
    "        byte[] bytes = Files.readAllBytes(Paths.get(filename.get(i)));\n",
    "        try {\n",
    "            Tensor<String> input = Tensors.create(bytes);\n",
    "            Tensor<Float> output =\n",
    "                     session\n",
    "                             .runner()\n",
    "                             .feed(\"encoded_image_bytes\", input)\n",
    "                             .fetch(\"probabilities\")\n",
    "                             .run()\n",
    "                             .get(0)\n",
    "                             .expect(Float.class)\n",
    "            if (probabilities == null) {\n",
    "                probabilities = new float[(int) output.shape()[0]];\n",
    "            }\n",
    "            output.copyTo(probabilities);\n",
    "            int label = argmax(probabilities);\n",
    "            System.out.printf(\n",
    "                    \"%-30s --> %-15s (%.2f%% likely)\\n\",\n",
    "                    filename.get(i), labels.get(label), probabilities[label] * 100.0);\n",
    "        } catch(Exception e){\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "} catch(Exception e){\n",
    "    e.printStackTrace();\n",
    "}\n",
    "\n",
    "private int argmax(float[] probabilities) {\n",
    "    int best = 0;\n",
    "    for (int i = 1; i < probabilities.length; ++i) {\n",
    "        if (probabilities[i] > probabilities[best]) {\n",
    "            best = i;\n",
    "        }\n",
    "    }\n",
    "    return best;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see another example of using a pre-trained model. Here, we'll use the `ssd_inception_v2_coco` model for object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SIGNATURE\n",
      "Inputs:\n",
      "1 of 1: inputs               (Node name in graph: image_tensor:0      , type: DT_UINT8)\n",
      "Outputs:\n",
      "1 of 4: num_detections       (Node name in graph: num_detections:0    , type: DT_FLOAT)\n",
      "2 of 4: detection_boxes      (Node name in graph: detection_boxes:0   , type: DT_FLOAT)\n",
      "3 of 4: detection_scores     (Node name in graph: detection_scores:0  , type: DT_FLOAT)\n",
      "4 of 4: detection_classes    (Node name in graph: detection_classes:0 , type: DT_FLOAT)\n",
      "-----------------------------------------------\n",
      "* ./assets/object_detection/test.jpg\n",
      "\tFound person               (score: 0.9877)\n",
      "\tFound person               (score: 0.9687)\n",
      "\tFound dog                  (score: 0.9489)\n",
      "\tFound person               (score: 0.9348)\n",
      "\tFound person               (score: 0.8712)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.tensorflow.SavedModelBundle;\n",
    "import org.tensorflow.Tensor;\n",
    "import org.tensorflow.framework.MetaGraphDef;\n",
    "import org.tensorflow.framework.SignatureDef;\n",
    "import org.tensorflow.framework.TensorInfo;\n",
    "import org.tensorflow.types.UInt8;\n",
    "\n",
    "import javax.imageio.ImageIO;\n",
    "import javax.swing.*;\n",
    "import java.awt.*;\n",
    "import java.awt.image.BufferedImage;\n",
    "import java.awt.image.DataBufferByte;\n",
    "import java.io.BufferedReader;\n",
    "import java.io.File;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "import java.nio.ByteBuffer;\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "import java.util.Map;\n",
    "\n",
    "final List<String> labels = new ArrayList<>();\n",
    "String line;\n",
    "BufferedReader reader = new BufferedReader(new FileReader(\"./assets/object_detection/object_label.txt\"));\n",
    "while ((line = reader.readLine()) != null) {\n",
    "    labels.add(line);\n",
    "}\n",
    "\n",
    "try{\n",
    "    SavedModelBundle model = SavedModelBundle.load(\"./assets/object_detection/ssd_inception_v2_coco_2017_11_17/saved_model\", \"serve\");\n",
    "    printSignature(model);\n",
    "    final String filename = \"./assets/object_detection/test.jpg\";\n",
    "    List<Tensor<?>> outputs = null;\n",
    "    try {\n",
    "        Tensor<UInt8> input = makeImageTensor(filename)\n",
    "        outputs =\n",
    "                model\n",
    "                        .session()\n",
    "                        .runner()\n",
    "                        .feed(\"image_tensor\", input)\n",
    "                        .fetch(\"detection_scores\")\n",
    "                        .fetch(\"detection_classes\")\n",
    "                        .fetch(\"detection_boxes\")\n",
    "                        .run();\n",
    "    }  catch(Exception e){\n",
    "        e.printStackTrace();\n",
    "    } \n",
    "    \n",
    "    try {\n",
    "        Tensor<Float> scoresT = outputs.get(0).expect(Float.class);\n",
    "        Tensor<Float> classesT = outputs.get(1).expect(Float.class);\n",
    "        Tensor<Float> boxesT = outputs.get(2).expect(Float.class);\n",
    "        int maxObjects = (int) scoresT.shape()[1];\n",
    "        float[] scores = scoresT.copyTo(new float[1][maxObjects])[0];\n",
    "        float[] classes = classesT.copyTo(new float[1][maxObjects])[0];\n",
    "        float[][] boxes = boxesT.copyTo(new float[1][maxObjects][4])[0];\n",
    "        \n",
    "        System.out.printf(\"* %s\\n\", filename);\n",
    "        \n",
    "        BufferedImage myPicture = ImageIO.read(new File(filename));\n",
    "        Graphics2D g = (Graphics2D) myPicture.getGraphics();\n",
    "        g.setStroke(new BasicStroke(3));\n",
    "        g.setFont(new Font(Font.MONOSPACED, Font.BOLD, 16));\n",
    "        List<Color> colors = new ArrayList<>();\n",
    "        colors.add(java.awt.Color.RED);\n",
    "        colors.add(java.awt.Color.ORANGE);\n",
    "        colors.add(java.awt.Color.BLUE);\n",
    "        \n",
    "        \n",
    "        boolean foundSomething = false;\n",
    "        // Print all objects whose score is at least 0.5.\n",
    "        for (int i = 0; i < scores.length; ++i) {\n",
    "            if (scores[i] < 0.5) {\n",
    "                continue;\n",
    "            }\n",
    "            foundSomething = true;\n",
    "            g.setColor(colors.get(i % colors.size()));\n",
    "            g.drawRect((int) (boxes[i][1] * myPicture.getWidth()), (int) (boxes[i][0] * myPicture.getHeight()), (int) ((boxes[i][3] - boxes[i][1]) * myPicture.getWidth()), (int) ((boxes[i][2] - boxes[i][0]) * myPicture.getHeight()));\n",
    "            g.drawString(labels.get((int) classes[i]) + \" \" + String.format(\"%.2f\", (scores[i] * 100)) + \"%\", (float)(boxes[i][1] * myPicture.getWidth()), (float)(boxes[i][0] * myPicture.getHeight()));\n",
    "            System.out.printf(\"\\tFound %-20s (score: %.4f)\\n\", labels.get((int) classes[i]), scores[i]);\n",
    "        }\n",
    "        if (!foundSomething) {\n",
    "            System.out.println(\"No objects detected with a high enough score.\");\n",
    "        }\n",
    "        \n",
    "        JLabel picLabel = new JLabel(new ImageIcon(myPicture));\n",
    "        JPanel jPanel = new JPanel();\n",
    "        jPanel.add(picLabel);\n",
    "        JFrame f = new JFrame();\n",
    "        f.setSize(new Dimension(myPicture.getWidth(), myPicture.getHeight()));\n",
    "        f.add(jPanel);\n",
    "        f.setVisible(false);\n",
    "        ImageIO.write(myPicture, \"jpg\", new File(\"./assets/object_detection/output.jpg\"));\n",
    "    } catch(Exception e){\n",
    "        e.printStackTrace();\n",
    "    }\n",
    "} catch(Exception e){\n",
    "    e.printStackTrace();\n",
    "}\n",
    "  \n",
    "private static void printSignature(SavedModelBundle model) throws Exception {\n",
    "    MetaGraphDef m = MetaGraphDef.parseFrom(model.metaGraphDef());\n",
    "    SignatureDef sig = m.getSignatureDefOrThrow(\"serving_default\");\n",
    "    int numInputs = sig.getInputsCount();\n",
    "    int i = 1;\n",
    "    System.out.println(\"MODEL SIGNATURE\");\n",
    "    System.out.println(\"Inputs:\");\n",
    "    for (Map.Entry<String, TensorInfo> entry : sig.getInputsMap().entrySet()) {\n",
    "        TensorInfo t = entry.getValue();\n",
    "        System.out.printf(\n",
    "                \"%d of %d: %-20s (Node name in graph: %-20s, type: %s)\\n\",\n",
    "                i++, numInputs, entry.getKey(), t.getName(), t.getDtype());\n",
    "    }\n",
    "    int numOutputs = sig.getOutputsCount();\n",
    "    i = 1;\n",
    "    System.out.println(\"Outputs:\");\n",
    "    for (Map.Entry<String, TensorInfo> entry : sig.getOutputsMap().entrySet()) {\n",
    "        TensorInfo t = entry.getValue();\n",
    "        System.out.printf(\n",
    "                \"%d of %d: %-20s (Node name in graph: %-20s, type: %s)\\n\",\n",
    "                i++, numOutputs, entry.getKey(), t.getName(), t.getDtype());\n",
    "    }\n",
    "    System.out.println(\"-----------------------------------------------\");\n",
    "}\n",
    "\n",
    "private static void bgr2rgb(byte[] data) {\n",
    "    for (int i = 0; i < data.length; i += 3) {\n",
    "        byte tmp = data[i];\n",
    "        data[i] = data[i + 2];\n",
    "        data[i + 2] = tmp;\n",
    "    }\n",
    "}\n",
    "\n",
    "private static Tensor<UInt8> makeImageTensor(String filename) throws IOException {\n",
    "    BufferedImage img = ImageIO.read(new File(filename));\n",
    "    if (img.getType() != BufferedImage.TYPE_3BYTE_BGR) {\n",
    "        throw new IOException(\n",
    "                String.format(\n",
    "                        \"Expected 3-byte BGR encoding in BufferedImage, found %d (file: %s). This code could be made more robust\",\n",
    "                        img.getType(), filename));\n",
    "    }\n",
    "    byte[] data = ((DataBufferByte) img.getData().getDataBuffer()).getData();\n",
    "    // ImageIO.read seems to produce BGR-encoded images, but the model expects RGB.\n",
    "    bgr2rgb(data);\n",
    "    final long BATCH_SIZE = 1;\n",
    "    final long CHANNELS = 3;\n",
    "    long[] shape = [BATCH_SIZE, img.getHeight(), img.getWidth(), CHANNELS];\n",
    "    return Tensor.create(UInt8.class, shape, ByteBuffer.wrap(data));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output images are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![input][1]][1]\n",
    "\n",
    "[1]: ./assets/object_detection/test.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![input][1]][1]\n",
    "\n",
    "[1]: ./assets/object_detection/output.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this model on other images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SIGNATURE\n",
      "Inputs:\n",
      "1 of 1: inputs               (Node name in graph: image_tensor:0      , type: DT_UINT8)\n",
      "Outputs:\n",
      "1 of 4: detection_scores     (Node name in graph: detection_scores:0  , type: DT_FLOAT)\n",
      "2 of 4: detection_classes    (Node name in graph: detection_classes:0 , type: DT_FLOAT)\n",
      "3 of 4: num_detections       (Node name in graph: num_detections:0    , type: DT_FLOAT)\n",
      "4 of 4: detection_boxes      (Node name in graph: detection_boxes:0   , type: DT_FLOAT)\n",
      "-----------------------------------------------\n",
      "* ./assets/object_detection/test2.jpeg\n",
      "\tFound bus                  (score: 0.9844)\n",
      "\tFound truck                (score: 0.8359)\n",
      "\tFound person               (score: 0.7873)\n",
      "\tFound person               (score: 0.7810)\n",
      "\tFound person               (score: 0.6311)\n",
      "\tFound person               (score: 0.6285)\n",
      "\tFound truck                (score: 0.5652)\n",
      "\tFound person               (score: 0.5507)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.tensorflow.SavedModelBundle;\n",
    "import org.tensorflow.Tensor;\n",
    "import org.tensorflow.framework.MetaGraphDef;\n",
    "import org.tensorflow.framework.SignatureDef;\n",
    "import org.tensorflow.framework.TensorInfo;\n",
    "import org.tensorflow.types.UInt8;\n",
    "\n",
    "import javax.imageio.ImageIO;\n",
    "import javax.swing.*;\n",
    "import java.awt.*;\n",
    "import java.awt.image.BufferedImage;\n",
    "import java.awt.image.DataBufferByte;\n",
    "import java.io.BufferedReader;\n",
    "import java.io.File;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "import java.nio.ByteBuffer;\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "import java.util.Map;\n",
    "\n",
    "final List<String> labels = new ArrayList<>();\n",
    "String line;\n",
    "BufferedReader reader = new BufferedReader(new FileReader(\"./assets/object_detection/object_label.txt\"));\n",
    "while ((line = reader.readLine()) != null) {\n",
    "    labels.add(line);\n",
    "}\n",
    "\n",
    "try{\n",
    "    SavedModelBundle model = SavedModelBundle.load(\"./assets/object_detection/ssd_inception_v2_coco_2017_11_17/saved_model\", \"serve\");\n",
    "    printSignature(model);\n",
    "    final String filename = \"./assets/object_detection/test2.jpeg\";\n",
    "    List<Tensor<?>> outputs = null;\n",
    "    try {\n",
    "        Tensor<UInt8> input = makeImageTensor(filename)\n",
    "        outputs =\n",
    "                model\n",
    "                        .session()\n",
    "                        .runner()\n",
    "                        .feed(\"image_tensor\", input)\n",
    "                        .fetch(\"detection_scores\")\n",
    "                        .fetch(\"detection_classes\")\n",
    "                        .fetch(\"detection_boxes\")\n",
    "                        .run();\n",
    "    }  catch(Exception e){\n",
    "        e.printStackTrace();\n",
    "    } \n",
    "    \n",
    "    try {\n",
    "        Tensor<Float> scoresT = outputs.get(0).expect(Float.class);\n",
    "        Tensor<Float> classesT = outputs.get(1).expect(Float.class);\n",
    "        Tensor<Float> boxesT = outputs.get(2).expect(Float.class);\n",
    "        int maxObjects = (int) scoresT.shape()[1];\n",
    "        float[] scores = scoresT.copyTo(new float[1][maxObjects])[0];\n",
    "        float[] classes = classesT.copyTo(new float[1][maxObjects])[0];\n",
    "        float[][] boxes = boxesT.copyTo(new float[1][maxObjects][4])[0];\n",
    "        \n",
    "        System.out.printf(\"* %s\\n\", filename);\n",
    "        \n",
    "        BufferedImage myPicture = ImageIO.read(new File(filename));\n",
    "        Graphics2D g = (Graphics2D) myPicture.getGraphics();\n",
    "        g.setStroke(new BasicStroke(3));\n",
    "        g.setFont(new Font(Font.MONOSPACED, Font.BOLD, 16));\n",
    "        List<Color> colors = new ArrayList<>();\n",
    "        colors.add(java.awt.Color.RED);\n",
    "        colors.add(java.awt.Color.ORANGE);\n",
    "        colors.add(java.awt.Color.BLUE);\n",
    "        \n",
    "        \n",
    "        boolean foundSomething = false;\n",
    "        // Print all objects whose score is at least 0.5.\n",
    "        for (int i = 0; i < scores.length; ++i) {\n",
    "            if (scores[i] < 0.5) {\n",
    "                continue;\n",
    "            }\n",
    "            foundSomething = true;\n",
    "            g.setColor(colors.get(i % colors.size()));\n",
    "            g.drawRect((int) (boxes[i][1] * myPicture.getWidth()), (int) (boxes[i][0] * myPicture.getHeight()), (int) ((boxes[i][3] - boxes[i][1]) * myPicture.getWidth()), (int) ((boxes[i][2] - boxes[i][0]) * myPicture.getHeight()));\n",
    "            g.drawString(labels.get((int) classes[i]) + \" \" + String.format(\"%.2f\", (scores[i] * 100)) + \"%\", (float)(boxes[i][1] * myPicture.getWidth()), (float)(boxes[i][0] * myPicture.getHeight()));\n",
    "            System.out.printf(\"\\tFound %-20s (score: %.4f)\\n\", labels.get((int) classes[i]), scores[i]);\n",
    "        }\n",
    "        if (!foundSomething) {\n",
    "            System.out.println(\"No objects detected with a high enough score.\");\n",
    "        }\n",
    "        \n",
    "        JLabel picLabel = new JLabel(new ImageIcon(myPicture));\n",
    "        JPanel jPanel = new JPanel();\n",
    "        jPanel.add(picLabel);\n",
    "        JFrame f = new JFrame();\n",
    "        f.setSize(new Dimension(myPicture.getWidth(), myPicture.getHeight()));\n",
    "        f.add(jPanel);\n",
    "        f.setVisible(false);\n",
    "        ImageIO.write(myPicture, \"jpg\", new File(\"./assets/object_detection/output.jpg\"));\n",
    "    } catch(Exception e){\n",
    "        e.printStackTrace();\n",
    "    }\n",
    "} catch(Exception e){\n",
    "    e.printStackTrace();\n",
    "}\n",
    "  \n",
    "private static void printSignature(SavedModelBundle model) throws Exception {\n",
    "    MetaGraphDef m = MetaGraphDef.parseFrom(model.metaGraphDef());\n",
    "    SignatureDef sig = m.getSignatureDefOrThrow(\"serving_default\");\n",
    "    int numInputs = sig.getInputsCount();\n",
    "    int i = 1;\n",
    "    System.out.println(\"MODEL SIGNATURE\");\n",
    "    System.out.println(\"Inputs:\");\n",
    "    for (Map.Entry<String, TensorInfo> entry : sig.getInputsMap().entrySet()) {\n",
    "        TensorInfo t = entry.getValue();\n",
    "        System.out.printf(\n",
    "                \"%d of %d: %-20s (Node name in graph: %-20s, type: %s)\\n\",\n",
    "                i++, numInputs, entry.getKey(), t.getName(), t.getDtype());\n",
    "    }\n",
    "    int numOutputs = sig.getOutputsCount();\n",
    "    i = 1;\n",
    "    System.out.println(\"Outputs:\");\n",
    "    for (Map.Entry<String, TensorInfo> entry : sig.getOutputsMap().entrySet()) {\n",
    "        TensorInfo t = entry.getValue();\n",
    "        System.out.printf(\n",
    "                \"%d of %d: %-20s (Node name in graph: %-20s, type: %s)\\n\",\n",
    "                i++, numOutputs, entry.getKey(), t.getName(), t.getDtype());\n",
    "    }\n",
    "    System.out.println(\"-----------------------------------------------\");\n",
    "}\n",
    "\n",
    "private static void bgr2rgb(byte[] data) {\n",
    "    for (int i = 0; i < data.length; i += 3) {\n",
    "        byte tmp = data[i];\n",
    "        data[i] = data[i + 2];\n",
    "        data[i + 2] = tmp;\n",
    "    }\n",
    "}\n",
    "\n",
    "private static Tensor<UInt8> makeImageTensor(String filename) throws IOException {\n",
    "    BufferedImage img = ImageIO.read(new File(filename));\n",
    "    if (img.getType() != BufferedImage.TYPE_3BYTE_BGR) {\n",
    "        throw new IOException(\n",
    "                String.format(\n",
    "                        \"Expected 3-byte BGR encoding in BufferedImage, found %d (file: %s). This code could be made more robust\",\n",
    "                        img.getType(), filename));\n",
    "    }\n",
    "    byte[] data = ((DataBufferByte) img.getData().getDataBuffer()).getData();\n",
    "    // ImageIO.read seems to produce BGR-encoded images, but the model expects RGB.\n",
    "    bgr2rgb(data);\n",
    "    final long BATCH_SIZE = 1;\n",
    "    final long CHANNELS = 3;\n",
    "    long[] shape = [BATCH_SIZE, img.getHeight(), img.getWidth(), CHANNELS];\n",
    "    return Tensor.create(UInt8.class, shape, ByteBuffer.wrap(data));\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output images are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![input][1]][1]\n",
    "\n",
    "[1]: ./assets/object_detection/test2.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![input][1]][1]\n",
    "\n",
    "[1]: ./assets/object_detection/output.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Groovy",
   "language": "groovy",
   "name": "groovy"
  },
  "language_info": {
   "codemirror_mode": "groovy",
   "file_extension": ".groovy",
   "mimetype": "",
   "name": "Groovy",
   "nbconverter_exporter": "",
   "version": "2.4.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
