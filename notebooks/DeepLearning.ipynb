{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as the supporting material for the chapter **Deep Learning**. In this notebook, we'll learn different activation funtions. Then we'll create a deep neural network using Deeplearning4j and train a model capable of classifying random handwriting digits. \n",
    "\n",
    ">_\"While handwriting recognition has been attempted by different machine learning algorithms over the years, deep learning performs remarkably well and achieves an accuracy of over 99.7% on the MNIST dataset.\"_ \n",
    "\n",
    "So, let's begin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab811e7f-535c-45e0-b97e-53739db5c227",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%classpath add mvn\n",
    "org.nd4j nd4j-native-platform 0.9.1\n",
    "org.deeplearning4j deeplearning4j-core 0.9.1\n",
    "org.datavec datavec-api 0.9.1\n",
    "org.datavec datavec-local 0.9.1\n",
    "org.datavec datavec-dataframe 0.9.1\n",
    "org.bytedeco javacpp 1.5\n",
    "org.apache.httpcomponents httpclient 4.3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "### 1.) Saturating activation funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957f024a-f47b-4ab2-a9d7-ce7b26f0c35b",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.nd4j.linalg.api.ndarray.INDArray;\n",
    "import org.nd4j.linalg.factory.Nd4j;\n",
    "import org.nd4j.linalg.ops.transforms.Transforms;\n",
    "import org.nd4j.linalg.api.iter.NdIndexIterator;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "INDArray array = Nd4j.linspace(-5,5,200);\n",
    "INDArray sigmoid = Transforms.sigmoid(array);\n",
    "\n",
    "def ch = new Crosshair(color: Color.gray, width: 2, style: StrokeType.DOT);\n",
    "p1 = new Plot(title: \"Sigmoid activation function\", crosshair: ch);\n",
    "p1 << new ConstantLine(x: 0, y: 0, color: Color.black);\n",
    "p1 << new ConstantLine(y: 1, color: Color.black, style: StrokeType.DOT);\n",
    "p1 << new Line(x: [-5, 5], y: [-3/4, 7/4], style: StrokeType.DASH, color: Color.green);\n",
    "p1 << new Line(x: toDoubleArrayList(array), y: toDoubleArrayList(sigmoid), displayName: \"Sigmoid\", color: Color.blue, width: 3);\n",
    "p1 << new Text(x: 0, y: 0.5, text: \"Linear\", pointerAngle: 3.505);\n",
    "p1 << new Text(x: -5, y: 0, text: \"Saturating\", pointerAngle: 1.57);\n",
    "p1 << new Text(x: 5, y: 1, text: \"Saturating\", pointerAngle: 4.71);\n",
    "\n",
    "public List<Double> toDoubleArrayList(INDArray array){\n",
    "    NdIndexIterator iter = new NdIndexIterator(200);\n",
    "    List<Double> list = new ArrayList<Double>();\n",
    "    while (iter.hasNext()) {\n",
    "        int[] nextIndex = iter.next();\n",
    "        double nextVal = array.getDouble(nextIndex);\n",
    "        list.add(nextVal);\n",
    "    }\n",
    "    return list;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faab4737-dfc3-49df-9be8-226bada2a083",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.nd4j.linalg.api.ndarray.INDArray;\n",
    "import org.nd4j.linalg.factory.Nd4j;\n",
    "import org.nd4j.linalg.ops.transforms.Transforms;\n",
    "import org.nd4j.linalg.api.iter.NdIndexIterator;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "INDArray array = Nd4j.linspace(-5,5,200);\n",
    "INDArray relu = Transforms.relu(array);\n",
    "INDArray leakyRelu = Transforms.leakyRelu(array);\n",
    "INDArray elu = Transforms.elu(array);\n",
    "\n",
    "def ch = new Crosshair(color: Color.gray, width: 2, style: StrokeType.DOT);\n",
    "p1 = new Plot(title: \"Non saturating activation function\", crosshair: ch);\n",
    "p1 << new ConstantLine(x: 0, y: 0, color: Color.black);\n",
    "p1 << new ConstantLine(y: -1, color: Color.black, style: StrokeType.DOT);\n",
    "p1.getYAxes()[0].setBound(-1.5,5);\n",
    "p1 << new Line(x: toDoubleArrayList(array), y: toDoubleArrayList(elu), displayName: \"ELU (Î±=1)\", color: Color.red)\n",
    "p1 << new Line(x: toDoubleArrayList(array), y: toDoubleArrayList(relu), displayName: \"ReLU\", color: Color.orange)\n",
    "p1 << new Line(x: toDoubleArrayList(array), y: toDoubleArrayList(leakyRelu), displayName: \"Leaky ReLU\", color: Color.blue);\n",
    "p1 << new Text(x: -5, y: 0, text: \"Leak\", pointerAngle: 1.57);\n",
    "\n",
    "\n",
    "public List<Double> toDoubleArrayList(INDArray array){\n",
    "    NdIndexIterator iter = new NdIndexIterator(200);\n",
    "    List<Double> list = new ArrayList<Double>();\n",
    "    while (iter.hasNext()) {\n",
    "        int[] nextIndex = iter.next();\n",
    "        double nextVal = array.getDouble(nextIndex);\n",
    "        list.add(nextVal);\n",
    "    }\n",
    "    return list;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on MNIST using the Leaky ReLU. \n",
    "\n",
    "We've to create a DataUtils class first, containing methods required for downloading, extracting and deleting the dataset files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package aima.notebooks.deeplearning;\n",
    "\n",
    "import org.apache.commons.compress.archivers.tar.TarArchiveEntry;\n",
    "import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\n",
    "import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\n",
    "import org.apache.http.HttpEntity;\n",
    "import org.apache.http.client.methods.CloseableHttpResponse;\n",
    "import org.apache.http.client.methods.HttpGet;\n",
    "import org.apache.http.impl.client.CloseableHttpClient;\n",
    "import org.apache.http.impl.client.HttpClientBuilder;\n",
    "\n",
    "import java.io.*;\n",
    "import java.nio.file.*;\n",
    "import java.nio.file.attribute.BasicFileAttributes;\n",
    "\n",
    "public class DataUtils{\n",
    "    \n",
    "    public DataUtils(){}\n",
    "    \n",
    "    public boolean downloadFile(String remoteUrl, String localPath) throws IOException {\n",
    "        boolean downloaded = false;\n",
    "        if (remoteUrl == null || localPath == null)\n",
    "            return downloaded;\n",
    "        File file = new File(localPath);\n",
    "        if (!file.exists()) {\n",
    "            file.getParentFile().mkdirs();\n",
    "            HttpClientBuilder builder = HttpClientBuilder.create();\n",
    "            CloseableHttpClient client = builder.build();\n",
    "            try {\n",
    "                CloseableHttpResponse response = client.execute(new HttpGet(remoteUrl))\n",
    "                HttpEntity entity = response.getEntity();\n",
    "                if (entity != null) {\n",
    "                    try {\n",
    "                        FileOutputStream outstream = new FileOutputStream(file)\n",
    "                        entity.writeTo(outstream);\n",
    "                        outstream.flush();\n",
    "                        outstream.close();\n",
    "                    } catch(IOException e){\n",
    "                        System.out.println(e);\n",
    "                    }\n",
    "                }\n",
    "            } catch(IOException e){\n",
    "                System.out.println(e);\n",
    "            }\n",
    "            downloaded = true;\n",
    "        }\n",
    "        if (!file.exists())\n",
    "            throw new IOException(\"File doesn't exist: \" + localPath);\n",
    "        return downloaded;\n",
    "    }\n",
    "    public void extractTarGz(String inputPath, String outputPath) throws IOException {\n",
    "        if (inputPath == null || outputPath == null)\n",
    "            return;\n",
    "        final int bufferSize = 4096;\n",
    "        if (!outputPath.endsWith(\"\" + File.separatorChar))\n",
    "            outputPath = outputPath + File.separatorChar;\n",
    "        try {\n",
    "            TarArchiveInputStream tais = new TarArchiveInputStream(new GzipCompressorInputStream(new BufferedInputStream(new FileInputStream(inputPath))))\n",
    "            TarArchiveEntry entry;\n",
    "            while ((entry = (TarArchiveEntry) tais.getNextEntry()) != null) {\n",
    "                if (entry.isDirectory()) {\n",
    "                    new File(outputPath + entry.getName()).mkdirs();\n",
    "                } else {\n",
    "                    int count;\n",
    "                    byte[] data = new byte[bufferSize];\n",
    "                    FileOutputStream fos = new FileOutputStream(outputPath + entry.getName());\n",
    "                    BufferedOutputStream dest = new BufferedOutputStream(fos, bufferSize);\n",
    "                    while ((count = tais.read(data, 0, bufferSize)) != -1) {\n",
    "                        dest.write(data, 0, count);\n",
    "                    }\n",
    "                    dest.close();\n",
    "                }\n",
    "            }\n",
    "        } catch(IOException e){\n",
    "            System.out.println(e);\n",
    "        }\n",
    "    }\n",
    "    public void deleteDir(String path) throws IOException{\n",
    "        Path directory = Paths.get(path);\n",
    "        Files.walkFileTree(directory, new SimpleFileVisitor<Path>() {\n",
    "            @Override\n",
    "            public FileVisitResult visitFile(Path file, BasicFileAttributes attributes) throws IOException {\n",
    "                Files.delete(file); // this will work because it's always a File\n",
    "                return FileVisitResult.CONTINUE;\n",
    "            }\n",
    "\n",
    "            @Override\n",
    "            public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {\n",
    "                Files.delete(dir); //this will work because Files in the directory are already deleted\n",
    "                return FileVisitResult.CONTINUE;\n",
    "            }\n",
    "        });\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aima.notebooks.deeplearning.DataUtils;\n",
    "import java.io.File;\n",
    "\n",
    "String DATA_URL = \"http://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz\";\n",
    "String BASE_PATH = \"./assets\";\n",
    "String localFilePath = BASE_PATH + \"/mnist_png.tar.gz\";\n",
    "DataUtils dataUtils = new DataUtils();\n",
    "if (!new File(localFilePath).exists()) {\n",
    "    if (dataUtils.downloadFile(DATA_URL, localFilePath)) {\n",
    "        dataUtils.extractTarGz(localFilePath, BASE_PATH);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Evaluation Stats*********\n",
      "\n",
      "Examples labeled as 0 classified by model as 0: 960 times\n",
      "Examples labeled as 0 classified by model as 2: 3 times\n",
      "Examples labeled as 0 classified by model as 3: 2 times\n",
      "Examples labeled as 0 classified by model as 4: 2 times\n",
      "Examples labeled as 0 classified by model as 5: 1 times\n",
      "Examples labeled as 0 classified by model as 6: 2 times\n",
      "Examples labeled as 0 classified by model as 7: 5 times\n",
      "Examples labeled as 0 classified by model as 8: 2 times\n",
      "Examples labeled as 0 classified by model as 9: 3 times\n",
      "Examples labeled as 1 classified by model as 1: 1124 times\n",
      "Examples labeled as 1 classified by model as 2: 2 times\n",
      "Examples labeled as 1 classified by model as 3: 1 times\n",
      "Examples labeled as 1 classified by model as 4: 1 times\n",
      "Examples labeled as 1 classified by model as 5: 1 times\n",
      "Examples labeled as 1 classified by model as 6: 3 times\n",
      "Examples labeled as 1 classified by model as 8: 3 times\n",
      "Examples labeled as 2 classified by model as 0: 3 times\n",
      "Examples labeled as 2 classified by model as 1: 2 times\n",
      "Examples labeled as 2 classified by model as 2: 1009 times\n",
      "Examples labeled as 2 classified by model as 3: 3 times\n",
      "Examples labeled as 2 classified by model as 4: 2 times\n",
      "Examples labeled as 2 classified by model as 6: 2 times\n",
      "Examples labeled as 2 classified by model as 7: 5 times\n",
      "Examples labeled as 2 classified by model as 8: 5 times\n",
      "Examples labeled as 2 classified by model as 9: 1 times\n",
      "Examples labeled as 3 classified by model as 2: 10 times\n",
      "Examples labeled as 3 classified by model as 3: 978 times\n",
      "Examples labeled as 3 classified by model as 5: 7 times\n",
      "Examples labeled as 3 classified by model as 7: 7 times\n",
      "Examples labeled as 3 classified by model as 8: 4 times\n",
      "Examples labeled as 3 classified by model as 9: 4 times\n",
      "Examples labeled as 4 classified by model as 2: 6 times\n",
      "Examples labeled as 4 classified by model as 4: 971 times\n",
      "Examples labeled as 4 classified by model as 6: 1 times\n",
      "Examples labeled as 4 classified by model as 8: 2 times\n",
      "Examples labeled as 4 classified by model as 9: 2 times\n",
      "Examples labeled as 5 classified by model as 0: 4 times\n",
      "Examples labeled as 5 classified by model as 2: 1 times\n",
      "Examples labeled as 5 classified by model as 3: 14 times\n",
      "Examples labeled as 5 classified by model as 4: 4 times\n",
      "Examples labeled as 5 classified by model as 5: 855 times\n",
      "Examples labeled as 5 classified by model as 6: 6 times\n",
      "Examples labeled as 5 classified by model as 7: 1 times\n",
      "Examples labeled as 5 classified by model as 8: 5 times\n",
      "Examples labeled as 5 classified by model as 9: 2 times\n",
      "Examples labeled as 6 classified by model as 0: 5 times\n",
      "Examples labeled as 6 classified by model as 1: 2 times\n",
      "Examples labeled as 6 classified by model as 2: 4 times\n",
      "Examples labeled as 6 classified by model as 3: 1 times\n",
      "Examples labeled as 6 classified by model as 4: 6 times\n",
      "Examples labeled as 6 classified by model as 5: 5 times\n",
      "Examples labeled as 6 classified by model as 6: 931 times\n",
      "Examples labeled as 6 classified by model as 7: 1 times\n",
      "Examples labeled as 6 classified by model as 8: 3 times\n",
      "Examples labeled as 7 classified by model as 1: 10 times\n",
      "Examples labeled as 7 classified by model as 2: 15 times\n",
      "Examples labeled as 7 classified by model as 3: 4 times\n",
      "Examples labeled as 7 classified by model as 4: 4 times\n",
      "Examples labeled as 7 classified by model as 5: 1 times\n",
      "Examples labeled as 7 classified by model as 7: 972 times\n",
      "Examples labeled as 7 classified by model as 8: 1 times\n",
      "Examples labeled as 7 classified by model as 9: 21 times\n",
      "Examples labeled as 8 classified by model as 0: 3 times\n",
      "Examples labeled as 8 classified by model as 2: 6 times\n",
      "Examples labeled as 8 classified by model as 3: 11 times\n",
      "Examples labeled as 8 classified by model as 4: 8 times\n",
      "Examples labeled as 8 classified by model as 5: 4 times\n",
      "Examples labeled as 8 classified by model as 6: 4 times\n",
      "Examples labeled as 8 classified by model as 7: 7 times\n",
      "Examples labeled as 8 classified by model as 8: 923 times\n",
      "Examples labeled as 8 classified by model as 9: 8 times\n",
      "Examples labeled as 9 classified by model as 0: 3 times\n",
      "Examples labeled as 9 classified by model as 1: 7 times\n",
      "Examples labeled as 9 classified by model as 2: 1 times\n",
      "Examples labeled as 9 classified by model as 3: 9 times\n",
      "Examples labeled as 9 classified by model as 4: 32 times\n",
      "Examples labeled as 9 classified by model as 5: 3 times\n",
      "Examples labeled as 9 classified by model as 7: 4 times\n",
      "Examples labeled as 9 classified by model as 8: 1 times\n",
      "Examples labeled as 9 classified by model as 9: 949 times\n",
      "\n",
      "\n",
      "==========================Scores========================================\n",
      " # of classes:    10\n",
      " Accuracy:        0.9672\n",
      " Precision:       0.9674\n",
      " Recall:          0.9669\n",
      " F1 Score:        0.9670\n",
      "Precision, recall & F1: macro-averaged (equally weighted avg. of 10 classes)\n",
      "========================================================================\n",
      "********Example finished*********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.datavec.api.io.labels.ParentPathLabelGenerator;\n",
    "import org.datavec.api.split.FileSplit;\n",
    "import org.datavec.image.loader.NativeImageLoader;\n",
    "import org.datavec.image.recordreader.ImageRecordReader;\n",
    "import org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator;\n",
    "import org.deeplearning4j.eval.Evaluation;\n",
    "import org.deeplearning4j.nn.api.OptimizationAlgorithm;\n",
    "import org.deeplearning4j.nn.conf.MultiLayerConfiguration;\n",
    "import org.deeplearning4j.nn.conf.NeuralNetConfiguration;\n",
    "import org.deeplearning4j.nn.conf.Updater;\n",
    "import org.deeplearning4j.nn.conf.inputs.InputType;\n",
    "import org.deeplearning4j.nn.conf.layers.DenseLayer;\n",
    "import org.deeplearning4j.nn.conf.layers.OutputLayer;\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\n",
    "import org.deeplearning4j.nn.weights.WeightInit;\n",
    "import org.deeplearning4j.optimize.listeners.ScoreIterationListener;\n",
    "import org.nd4j.linalg.activations.Activation;\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.DataNormalization;\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.ImagePreProcessingScaler;\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions;\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "import java.io.File;\n",
    "import java.util.Random;\n",
    "\n",
    "int seed = 123;\n",
    "double learningRate = 0.01;\n",
    "int batchSize = 100;\n",
    "int numEpochs = 1;\n",
    "\n",
    "int height = 28;\n",
    "int width = 28;\n",
    "int numInput = height * width;\n",
    "int numHidden = 1000;\n",
    "int numOutput = 10;\n",
    "\n",
    "//Prepare data for loading\n",
    "File trainData = new File(\"./assets/mnist_png/training\");\n",
    "FileSplit trainSplit = new FileSplit(trainData, NativeImageLoader.ALLOWED_FORMATS, new Random(seed));\n",
    "ParentPathLabelGenerator labelMaker = new ParentPathLabelGenerator(); // use parent directory name as the image label\n",
    "ImageRecordReader trainRR = new ImageRecordReader(height, width, 1, labelMaker);\n",
    "trainRR.initialize(trainSplit);\n",
    "DataSetIterator trainIter = new RecordReaderDataSetIterator(trainRR, batchSize, 1, numOutput);\n",
    "DataNormalization imageScaler = new ImagePreProcessingScaler();\n",
    "imageScaler.fit(trainIter);\n",
    "trainIter.setPreProcessor(imageScaler);\n",
    "\n",
    "\n",
    "File testData = new File(\"./assets/mnist_png/testing\");\n",
    "FileSplit testSplit = new FileSplit(testData, NativeImageLoader.ALLOWED_FORMATS, new Random(seed));\n",
    "ImageRecordReader testRR = new ImageRecordReader(height, width, 1, labelMaker);\n",
    "testRR.initialize(testSplit);\n",
    "DataSetIterator testIter = new RecordReaderDataSetIterator(testRR, batchSize, 1, numOutput);\n",
    "testIter.setPreProcessor(imageScaler);\n",
    "\n",
    "//Build the neural network\n",
    "MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()\n",
    "        .seed(seed)\n",
    "        .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n",
    "        .updater(Updater.ADAM)\n",
    "        .list()\n",
    "        .layer(0, new DenseLayer.Builder()\n",
    "                .nIn(numInput)\n",
    "                .nOut(numHidden)\n",
    "                .activation(Activation.RELU)\n",
    "                .weightInit(WeightInit.XAVIER)\n",
    "                .build())\n",
    "        .layer(1, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n",
    "                .nIn(numHidden)\n",
    "                .nOut(numOutput)\n",
    "                .activation(Activation.SOFTMAX)\n",
    "                .weightInit(WeightInit.XAVIER)\n",
    "                .build())\n",
    "        .setInputType(InputType.convolutional(28, 28, 1))\n",
    "        .build();\n",
    "\n",
    "MultiLayerNetwork model = new MultiLayerNetwork(conf);\n",
    "model.init();\n",
    "\n",
    "//Train the model and evaluate\n",
    "for (int i = 0; i < numEpochs; i++) {\n",
    "    model.fit(trainIter);\n",
    "    System.out.println(\"********Evaluation Stats*********\");\n",
    "    Evaluation eval = model.evaluate(testIter);\n",
    "    System.out.println(eval.stats());\n",
    "\n",
    "    trainIter.reset();\n",
    "    testIter.reset();\n",
    "}\n",
    "\n",
    "System.out.println(\"********Example finished*********\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delete the MNIST dataset files as they are no longer required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aima.notebooks.deeplearning.DataUtils;\n",
    "import java.io.File;\n",
    "\n",
    "String DATA_URL = \"http://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz\";\n",
    "String BASE_PATH = \"./assets\";\n",
    "String localFilePath = BASE_PATH + \"/mnist_png.tar.gz\";\n",
    "\n",
    "File file = new File(localFilePath);\n",
    "file.delete();\n",
    "DataUtils dataUtils = new DataUtils();\n",
    "dataUtils.deleteDir(BASE_PATH + \"/mnist_png\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Groovy",
   "language": "groovy",
   "name": "groovy"
  },
  "language_info": {
   "codemirror_mode": "groovy",
   "file_extension": ".groovy",
   "mimetype": "",
   "name": "Groovy",
   "nbconverter_exporter": "",
   "version": "2.4.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
