{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Reasoning\n",
    "\n",
    "This notebook serves as the supporting material for chapter 14**Probabilistic Reasoning**. In this notebook, we will learn how to use the code respository to build network models to reason under uncertainty according to the laws of probability theory. In the previous notebook, we briefly explained what Bayes' Rule is and how it can be utilised in Probabilistic Inference. This notebook introduces a systematic way to represent such conditional relationships in the form of **Bayesian Networks**. We will also have a look at a variety of approximate inference algorithms and will also explore ways in which probability theory can be applied to worlds with objects and relations(worlds represented in first order logic).\n",
    "\n",
    "## Representing knowledge in an uncertain domain\n",
    "\n",
    "We saw in the previous notebooks that the full joint probability distribution models can answer any question about the domain but they are computationally expensive as the space complexity grows exponentially. However, we saw that independence and conditional independence relationships among variables can be of great help in defining a full joint distribution. Owing to these shortcomings of full joint distributions and to the merits of conditional relations between random variables, AI researchers have come up with a clever data structure called Bayesian Networks. Bayesian networks can represent essentially any full joint probability distribution and in many cases can do so very concisely.\n",
    "\n",
    "A Bayesian network is a directed graph in which each node is annotated with quantitative probability information. The full specification is as follows:\n",
    "* Each node corresponds to a random variable, which may be discrete or continuous.\n",
    "* A set of directed links or arrows connects pairs of nodes. If there is an arrow from node X to node Y , X is said to be a parent of Y. The graph has no directed cycles (and hence is a directed acyclic graph, or DAG).\n",
    "* Each node $X_i$ has a conditional probability distribution $P(X_i \\mid Parents(X_i ))$ that quantifies the effect of the parents on the node.\n",
    "\n",
    "The topology of the network—the set of nodes and links—specifies the conditional independence relationships that hold in the domain. The\n",
    "intuitive meaning of an arrow is typically that X has a direct influence on Y, which suggests\n",
    "that causes should be parents of effects. It is usually easy for a domain expert to decide what\n",
    "direct influences exist in the domain—much easier, in fact, than actually specifying the probabilities themselves. Once the topology of the Bayesian network is laid out, we need only\n",
    "specify a conditional probability distribution for each variable, given its parents.\n",
    "\n",
    "The Bayesian Networks possess many interesting properties which are quite brilliantly explained in the text. Readers are advised to go through the text to get a feel for the Bayesian Networks. In this notebook, our main focus will be to utilise Bayesian Networks to model various problems.\n",
    "\n",
    "To work with the Bayesian Networks let us first load the aima jar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cf7a35-5540-4e74-ac94-07cb97cbaf68",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add jar ../out/artifacts/aima_core_jar/aima-core.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tooth cavity catch structure\n",
    "\n",
    "Consider the simple world described in the text, consisting of variables *Toothache, Cavity, Catch* and *Weather*. It is easy to see that *Weather* is independent of other variables. Furthermore it can be argued that *Toothache* and *Catch* are conditionally independent given *Cavity*. These relationships can be represented by a Bayesian Network structure shown below. Formally, the conditional independence of *Toothache* and *Catch*, given\n",
    "Cavity, is indicated by the absence of a link between *Toothache* and *Catch*. Intuitively, the\n",
    "network represents the fact that *Cavity* is a direct cause of *Toothache* and *Catch*, whereas\n",
    "no direct causal relationship exists between Toothache and Catch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIs from the code repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the structure of APIs from the code repository. We will understand the APIs by considering the three defining points of the Bayesian Networks.\n",
    "\n",
    "**Each node corresponds to a random variable, which may be discrete or continuous.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Node` interface represents the node in a Bayesian Network. Given below is a description of the Node interface.\n",
    "````java\n",
    "public interface Node {\n",
    "\n",
    "\t/**\n",
    "\t * \n",
    "\t * @return the Random Variable this Node is for/on.\n",
    "\t */\n",
    "\tRandomVariable getRandomVariable();\n",
    "\n",
    "\t/**\n",
    "\t * \n",
    "\t * @return true if this Node has no parents.\n",
    "\t * \n",
    "\t * @see Node#getParents()\n",
    "\t */\n",
    "\tboolean isRoot();\n",
    "\n",
    "\t/**\n",
    "\t * \n",
    "\t * @return the parent Nodes for this Node.\n",
    "\t */\n",
    "\tSet<Node> getParents();\n",
    "\n",
    "\t/**\n",
    "\t * \n",
    "\t * @return the children Nodes for this Node.\n",
    "\t */\n",
    "\tSet<Node> getChildren();\n",
    "\n",
    "\t/**\n",
    "\t * Get this Node's Markov Blanket:<br>\n",
    "\t * 'A node is conditionally independent of all other nodes in the network,\n",
    "\t * given its parents, children, and children's parents - that is, given its\n",
    "\t * <b>MARKOV BLANKET</b> (AIMA3e pg, 517).\n",
    "\t * \n",
    "\t * @return this Node's Markov Blanket.\n",
    "\t */\n",
    "\tSet<Node> getMarkovBlanket();\n",
    "\n",
    "\t/**\n",
    "\t * \n",
    "\t * @return the Conditional Probability Distribution associated with this\n",
    "\t *         Node.\n",
    "\t */\n",
    "\tConditionalProbabilityDistribution getCPD();\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface can be implemented to obtain customised nodes. A default implementation is provided in the repository via the `FullCPTNode` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second specification of the Bayesian Networks tells about the hierarchy of the network.\n",
    "\n",
    "**A set of directed links or arrows connects pairs of nodes. If there is an arrow from node X to node Y , X is said to be a parent of Y. The graph has no directed cycles (and hence is a directed acyclic graph, or DAG).**\n",
    "\n",
    "These links are stored as a set and can be obtained by the `getParents()` method of the `Node` interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third specification states the data contained in each node.\n",
    "\n",
    "**Each node $X_i$ has a conditional probability distribution $P(X_i \\mid Parents(X_i ))$ that quantifies the effect of the parents on the node.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information is stored in the form of a ConditionalProbabilityDistribution inside a node. After we have defined the nodes for our network, we can use the `BayesNet` class from the repository and then construct a Bayesian Network. Let's work with the ToothAcheCavityAndCatch example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Variables = [Cavity, Toothache, Catch]\n",
      "The cavity Node: Cavity\n",
      "The toothache Node: Toothache\n",
      "The catch Node: Catch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "aima.core.probability.bayes.impl.BayesNet@5a94841e"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package aima.notebooks.probabilisticreasoning;\n",
    "\n",
    "import aima.core.probability.bayes.*;\n",
    "import aima.core.probability.*;\n",
    "import aima.core.probability.bayes.impl.*;\n",
    "import aima.core.probability.util.*;\n",
    "import aima.core.probability.domain.*;\n",
    "\n",
    "// First let us define the Random Variables which make up our Bayes Network\n",
    "RandVar cavityRv = new RandVar(\"Cavity\", new BooleanDomain());\n",
    "RandVar toothacheRv = new RandVar(\"Toothache\", new BooleanDomain());\n",
    "RandVar catchRv = new RandVar(\"Catch\", new BooleanDomain());\n",
    "\n",
    "// Now we will define the nodes that make up the network and represent the above network\n",
    "// the order of the doubles in CPT is as follows\n",
    "// If A,B and C are the three random variables then first the possibilities of C will be exhausted, then B and then A.\n",
    "// For example if A, B and C are Boolean random variables then the doubles will be mentioned in the given order\n",
    "//    A    B    C\n",
    "//    1    1    1\n",
    "//    1    1    0\n",
    "//    1    0    1\n",
    "//    1    0    0\n",
    "//    0    1    1\n",
    "//    0    1    0\n",
    "//    0    0    1\n",
    "//    0    0    0\n",
    "FullCPTNode cavity = new FullCPTNode(cavityRv, new double[] {\n",
    "                                    // True\t\t\t\n",
    "                                    0.2,\n",
    "                                    // False\n",
    "                                    0.8 });\n",
    "FullCPTNode toothache = new FullCPTNode(toothacheRv,\n",
    "\t\t\t\tnew double[] {\n",
    "\t\t\t\t\t\t// C=true, T=true\n",
    "\t\t\t\t\t\t0.6,\n",
    "\t\t\t\t\t\t// C=true, T=false\n",
    "\t\t\t\t\t\t0.4,\n",
    "\t\t\t\t\t\t// C=false, T=true\n",
    "\t\t\t\t\t\t0.1,\n",
    "\t\t\t\t\t\t// C=false, T=false\n",
    "\t\t\t\t\t\t0.9\n",
    "\n",
    "\t\t\t\t}, cavity);\n",
    "\n",
    "FiniteNode catchNode = new FullCPTNode(catchRv, new double[] {\n",
    "\t\t\t\t// C=true, Catch=true\n",
    "\t\t\t\t0.9,\n",
    "\t\t\t\t// C=true, Catch=false\n",
    "\t\t\t\t0.1,\n",
    "\t\t\t\t// C=false, Catch=true\n",
    "\t\t\t\t0.2,\n",
    "\t\t\t\t// C=false, Catch=false\n",
    "\t\t\t\t0.8 }, cavity);\n",
    "\n",
    "// Now let us consider the Bayesian network\n",
    "// We need to specify only the root nodes from the nerwork\n",
    "BayesNet cavityBayesNet = new BayesNet(cavity);\n",
    "\n",
    "// Now let's extract whatever we can from the BayesNet\n",
    "System.out.println(\"Random Variables = \"+ cavityBayesNet.getVariablesInTopologicalOrder().toString());\n",
    "System.out.println(\"The cavity Node: \"+ cavityBayesNet.getNode(cavityRv).toString());\n",
    "return cavityBayesNet;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above block describes how to construct a Bayesian Network. However, a Bayesian Network itself is of little use. Hence,we need inference algorithms which can extract information from the network. Before, introducing various inference algorithms, we must note that a **Bayesian Network** is capable of describing a **Full Joint Distribution** by itself. This can be shown by considering the fact that a generic entry in the joint distribution is the probability of a conjunction of particular\n",
    "assignments to each variable, such as $P (X_1 = x_1 \\land . . . \\land X_n = x_n )$. We use the notation\n",
    "$P (x_1 , . . . , x_n )$ as an abbreviation for this. Now, in terms of conditional probability, using the product rule\n",
    "\n",
    "$$P (x_1 , . . . , x_n ) = P (x_n | x_{n−1} , . . . , x_1 )P (x_{n−1} , . . . , x_1 )$$\n",
    "\n",
    "Then we repeat the process, reducing each conjunctive probability to a conditional probability\n",
    "and a smaller conjunction. We end up with one big product:\n",
    "\n",
    "$$P (x 1 , . . . , x n ) = P (x n | x n−1 , . . . , x 1 )P (x n−1 | x n−2 , . . . , x 1 ) · · · P (x 2 | x_1 )P (x_1 )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "text/x-java",
   "file_extension": ".java",
   "mimetype": "",
   "name": "Java",
   "nbconverter_exporter": "",
   "version": "1.8.0_161"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
